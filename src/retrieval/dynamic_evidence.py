"""
Dynamic Evidence Pipeline: ë™ì  ê·¼ê±° ê°•í™” ì‹œìŠ¤í…œ
================================================
Phase 7ì˜ í•µì‹¬: PMC ì „ë¬¸ ì‹¤ì‹œê°„ ì¸ì¶œ + ê·¼ê±° ì¶”ì  + Phase 6 ì¶”ë¡ ì„ í†µí•©

Workflow:
    1. [Search] ì´ˆë¡ ê¸°ë°˜ ê²€ìƒ‰ìœ¼ë¡œ í›„ë³´ ë…¼ë¬¸ ì„ ì •
    2. [Fetch] PMC ID ë³´ìœ  ë…¼ë¬¸ì˜ ì „ë¬¸ì„ ë¹„ë™ê¸°ë¡œ ì¸ì¶œ
    3. [Chunk] ì§ˆë¬¸ ê´€ë ¨ ì„¹ì…˜ë§Œ ìŠ¤ë§ˆíŠ¸ ì¶”ì¶œ
    4. [Reason] Phase 6 Answering Twiceë¡œ ì‹¬ì¸µ ì¶”ë¡ 
    5. [Map] Evidence Mapperë¡œ ê·¼ê±° ì¶œì²˜ ì¶”ì 
    6. [Output] êµ¬ì¡°í™”ëœ ë‹µë³€ + ê·¼ê±° ì¸ìš©

"ì œê°€ PMCì—ì„œ í•´ë‹¹ ë…¼ë¬¸ ì „ë¬¸ì„ í™•ì¸í•´ë³¸ ê²°ê³¼..."
"""

import asyncio
import logging
from typing import Optional, Dict, Any, List, Tuple
from dataclasses import dataclass, field

from src.retrieval.pmc_fetcher import PMCFetcher, PMCArticle, get_pmc_fetcher
from src.retrieval.summarizer import MedicalTextSummarizer, get_medical_summarizer, SummaryResult
from src.reasoning.evidence_mapper import EvidenceMapper, EvidenceReport, get_evidence_mapper
from src.reasoning.text_logic import TextReasoningEngine, RefinedAnswer, get_text_reasoning_engine
from src.evaluation.agent_judge import AgentJudge, JudgeResult, JudgeVerdict, get_agent_judge
from src.knowledge.manager import KnowledgeManager, get_knowledge_manager
# Phase 7.6: Agentic Orchestrator
from src.reasoning.orchestrator import AgenticOrchestrator, get_agentic_orchestrator, OrchestrationResult

logger = logging.getLogger(__name__)


@dataclass
class EnrichedContext:
    """ê°•í™”ëœ ì»¨í…ìŠ¤íŠ¸"""
    original_context: str           # ì´ˆë¡ ê¸°ë°˜ ì›ë³¸ ì»¨í…ìŠ¤íŠ¸
    enriched_context: str           # PMC ì „ë¬¸ìœ¼ë¡œ ê°•í™”ëœ ì»¨í…ìŠ¤íŠ¸
    pmc_articles: List[PMCArticle]  # ì¸ì¶œëœ PMC ë…¼ë¬¸ë“¤
    fetched_count: int              # ì¸ì¶œëœ ë…¼ë¬¸ ìˆ˜
    total_chars: int                # ì´ ë¬¸ì ìˆ˜
    used_fulltext: bool = False     # ì „ë¬¸ ì‚¬ìš© ì—¬ë¶€
    used_summarizer: bool = False   # SLM ìš”ì•½ ì‚¬ìš© ì—¬ë¶€ (Phase 7.1)


@dataclass
class DynamicEvidenceResult:
    """ë™ì  ê·¼ê±° ê°•í™” ê²°ê³¼"""
    answer: str                     # ìµœì¢… ë‹µë³€ (êµ¬ì¡°í™”)
    refined_answer: RefinedAnswer   # Phase 6 ì¶”ë¡  ê²°ê³¼
    judge_result: JudgeResult       # í’ˆì§ˆ í‰ê°€ ê²°ê³¼
    evidence_report: EvidenceReport # ê·¼ê±° ë§¤í•‘ ë³´ê³ ì„œ
    enriched_context: EnrichedContext  # ê°•í™”ëœ ì»¨í…ìŠ¤íŠ¸
    used_fulltext: bool             # ì „ë¬¸ ì‚¬ìš© ì—¬ë¶€
    used_summarizer: bool = False   # SLM ìš”ì•½ ì‚¬ìš© ì—¬ë¶€ (Phase 7.1)


class DynamicEvidencePipeline:
    """
    ë™ì  ê·¼ê±° ê°•í™” íŒŒì´í”„ë¼ì¸

    Usage:
        pipeline = DynamicEvidencePipeline()

        result = await pipeline.process_async(
            question="DBTì—ì„œ 5cm ìœ ë°©ì˜ MGD ê³„ì‚° ì‹œ T-factorëŠ”?",
            papers=[{"pmid": "123", "pmc_id": "PMC456", "abstract": "..."}],
            physics_knowledge="..."
        )

        print(result.answer)
        print(f"ì „ë¬¸ ì‚¬ìš©: {result.used_fulltext}")
    """

    def __init__(self, use_summarizer: bool = True, enable_decomposition: bool = True):
        self.pmc_fetcher = get_pmc_fetcher()
        self.summarizer = get_medical_summarizer() if use_summarizer else None
        self.evidence_mapper = get_evidence_mapper()
        self.reasoning_engine = get_text_reasoning_engine()
        self.judge = get_agent_judge()
        self.knowledge_manager = get_knowledge_manager()
        self.use_summarizer = use_summarizer
        # Phase 7.6: Agentic Orchestrator
        self.enable_decomposition = enable_decomposition
        self.orchestrator = get_agentic_orchestrator() if enable_decomposition else None

    async def process_async(
        self,
        question: str,
        papers: List[Dict[str, Any]],
        physics_knowledge: str = "",
        max_pmc_fetch: int = 3
    ) -> DynamicEvidenceResult:
        """
        ë¹„ë™ê¸° ë™ì  ê·¼ê±° ê°•í™” ì²˜ë¦¬

        Args:
            question: ì‚¬ìš©ì ì§ˆë¬¸
            papers: ê²€ìƒ‰ëœ ë…¼ë¬¸ ëª©ë¡ (pmid, pmc_id, abstract í¬í•¨)
            physics_knowledge: KnowledgeManager ì§€ì‹
            max_pmc_fetch: ìµœëŒ€ PMC ì¸ì¶œ ìˆ˜

        Returns:
            DynamicEvidenceResult
        """
        logger.info(f"Processing with dynamic evidence: {question[:50]}...")

        # 1. PMC IDê°€ ìˆëŠ” ë…¼ë¬¸ í•„í„°ë§ ë° ì „ë¬¸ ì¸ì¶œ
        enriched_context = await self._enrich_context_async(
            question, papers, max_pmc_fetch
        )

        # 2. Phase 6 Answering Twice ì¶”ë¡ 
        combined_context = self._build_combined_context(
            enriched_context, physics_knowledge
        )

        refined_answer = self.reasoning_engine.reason(
            question=question,
            context=combined_context,
            physics_knowledge=physics_knowledge,
            require_derivation=True
        )

        # Phase 7.16: ë¹ˆ ì‘ë‹µ ê²€ì¦ ë° ì¬ì‹œë„
        if not refined_answer.content.strip():
            logger.warning("LLM ì‘ë‹µì´ ë¹„ì–´ìˆìŒ - ë‹¨ìˆœ ëª¨ë“œë¡œ ì¬ì‹œë„")
            # ì¬ì‹œë„: ë” ì§§ì€ ì»¨í…ìŠ¤íŠ¸ë¡œ
            retry_answer = self.reasoning_engine.reason(
                question=question,
                context="",  # ì»¨í…ìŠ¤íŠ¸ ì œê±°
                physics_knowledge=physics_knowledge[:3000] if physics_knowledge else "",
                require_derivation=False
            )
            if retry_answer.content.strip():
                refined_answer = retry_answer
            else:
                # ìµœì¢… ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ ë©”ì‹œì§€
                from src.reasoning.text_logic import RefinedAnswer, AnswerQuality
                refined_answer = RefinedAnswer(
                    content="ì£„ì†¡í•©ë‹ˆë‹¤. ì‘ë‹µ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ì§ˆë¬¸ì„ ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì„¸ìš”.",
                    derivation="",
                    evidence_mapping=[],
                    recommendation="",
                    quality=AnswerQuality.UNRELIABLE,
                    corrections_made=["LLM ì‘ë‹µ ìƒì„± ì‹¤íŒ¨"],
                    final_confidence=0.0,
                    clinical_insight=""
                )

        # 3. Agent-as-a-Judge í‰ê°€
        judge_result = self.judge.evaluate(
            question=question,
            answer=refined_answer.content,
            derivation=refined_answer.derivation,
            reference_knowledge=physics_knowledge,
            context=combined_context[:3000]
        )

        # 4. Evidence Mapping
        all_sources = self._build_source_list(papers, enriched_context.pmc_articles)
        evidence_report = self.evidence_mapper.analyze_answer(
            refined_answer.content, all_sources
        )

        # 5. ìµœì¢… ë‹µë³€ í¬ë§·íŒ…
        formatted_answer = self._format_final_answer(
            refined_answer, evidence_report, enriched_context.used_fulltext
        )

        return DynamicEvidenceResult(
            answer=formatted_answer,
            refined_answer=refined_answer,
            judge_result=judge_result,
            evidence_report=evidence_report,
            enriched_context=enriched_context,
            used_fulltext=enriched_context.fetched_count > 0,
            used_summarizer=enriched_context.used_summarizer
        )

    def process_sync(
        self,
        question: str,
        papers: List[Dict[str, Any]],
        physics_knowledge: str = "",
        max_pmc_fetch: int = 3
    ) -> DynamicEvidenceResult:
        """ë™ê¸° ë°©ì‹ ì²˜ë¦¬ (ë˜í¼)"""
        return asyncio.run(self.process_async(
            question, papers, physics_knowledge, max_pmc_fetch
        ))

    # =========================================================================
    # Phase 7.17: Simplified Pipeline (ë³µì¡í•œ ë ˆì´ì–´ ì œê±°)
    # =========================================================================

    async def process_simple_async(
        self,
        question: str,
        papers: List[Dict[str, Any]],
        physics_knowledge: str = "",
        max_pmc_fetch: int = 2
    ) -> DynamicEvidenceResult:
        """
        ë‹¨ìˆœí™”ëœ íŒŒì´í”„ë¼ì¸ (Phase 7.17)

        ë³µì¡í•œ ë ˆì´ì–´ë“¤ì„ ëª¨ë‘ ì œê±°í•˜ê³  ê¸°ë³¸ RAG + LLMë§Œ ì‚¬ìš©:
        - QueryPlanner ë¶„í•´ âŒ
        - PhysicsTriage ë¶„ë¥˜ âŒ
        - MathVerifier ê²€ì¦ âŒ
        - ReflectiveEngine íŒíŠ¸ âŒ
        - ResponseSynthesizer í•©ì„± âŒ

        ë‹¨ìˆœ íë¦„: Question â†’ Knowledge â†’ LLM â†’ Answer
        """
        logger.info(f"[SIMPLE] Processing: {question[:50]}...")

        # 1. PMC ì»¨í…ìŠ¤íŠ¸ (ì„ íƒì , ìµœì†Œí™”)
        enriched_context = await self._enrich_context_async(
            question, papers, max_pmc_fetch
        )

        # 2. CQO/QOCO í”„ë¡¬í”„íŠ¸ êµ¬ì„± (Phase 1: Lost in the Prompt Order)
        prompt_strategy = self._select_prompt_strategy(question)
        if prompt_strategy == "qoco":
            simple_prompt = self._build_qoco_prompt(
                question, physics_knowledge, enriched_context
            )
            logger.info(f"[SIMPLE] Using QOCO prompt strategy (calculation/comparison)")
        else:
            simple_prompt = self._build_simple_prompt(
                question, physics_knowledge, enriched_context
            )
            logger.info(f"[SIMPLE] Using CQO prompt strategy (concept/principle)")

        # 3. ì§ì ‘ LLM í˜¸ì¶œ (ë‹¨ì¼ ë‹¨ê³„)
        import requests
        try:
            response = requests.post(
                "http://localhost:11434/api/generate",
                json={
                    "model": "gpt-oss:20b",
                    "prompt": simple_prompt,
                    "stream": False,
                    "options": {
                        "temperature": 0.3,
                        "num_predict": 3000,
                        "num_ctx": 8192
                    }
                },
                timeout=300
            )
            response.raise_for_status()
            answer_content = response.json().get("response", "").strip()

            if not answer_content:
                answer_content = "ì‘ë‹µ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤."
                confidence = 0.0
            else:
                confidence = 0.85  # ë‹¨ìˆœ íŒŒì´í”„ë¼ì¸ ê¸°ë³¸ ì‹ ë¢°ë„

        except Exception as e:
            logger.error(f"[SIMPLE] LLM í˜¸ì¶œ ì‹¤íŒ¨: {e}")
            answer_content = f"ì˜¤ë¥˜ ë°œìƒ: {str(e)}"
            confidence = 0.0

        # 4. ìµœì†Œ í›„ì²˜ë¦¬ (LaTeX ë“±)
        answer_content = self._simple_postprocess(answer_content)

        # 5. ê²°ê³¼ ë°˜í™˜ (ê°„ì†Œí™”ëœ êµ¬ì¡° + ì „ëµ ì •ë³´)
        from src.reasoning.text_logic import RefinedAnswer, AnswerQuality
        from src.evaluation.agent_judge import JudgeResult, JudgeVerdict, EvaluationCriteria
        from src.reasoning.evidence_mapper import EvidenceReport

        refined = RefinedAnswer(
            content=answer_content,
            derivation="",
            evidence_mapping=[],
            recommendation="",
            quality=AnswerQuality.GOOD if confidence > 0.5 else AnswerQuality.UNRELIABLE,
            corrections_made=[],
            final_confidence=confidence,
            clinical_insight=""
        )

        # í‰ê°€ ìƒëµ (ì†ë„ ìš°ì„ ) - ê¸°ë³¸ê°’ ì‚¬ìš©
        default_criteria = EvaluationCriteria(
            factual_accuracy=confidence * 100,
            logical_consistency=confidence * 100,
            guideline_compliance=confidence * 100,
            completeness=confidence * 100,
            clinical_insight=confidence * 100
        )
        judge_result = JudgeResult(
            verdict=JudgeVerdict.APPROVED if confidence > 0.5 else JudgeVerdict.REVISION_REQUIRED,
            total_score=confidence * 100,
            criteria=default_criteria,
            issues_found=[],
            suggestions=[],
            reasoning="[SIMPLE MODE] í‰ê°€ ìƒëµ"
        )

        evidence_report = EvidenceReport(
            mapped_claims=[],
            total_claims=0,
            verified_claims=0,
            gold_sources=0,
            high_sources=0,
            overall_credibility=confidence
        )

        # í¬ë§·íŒ… (í”„ë¡¬í”„íŠ¸ ì „ëµ í‘œì‹œ)
        strategy_label = "CQO" if prompt_strategy == "cqo" else "QOCO"
        formatted = f"""## ë‹µë³€

{answer_content}

---
*[Phase 1: {strategy_label} í”„ë¡¬í”„íŠ¸] ì‹ ë¢°ë„: {confidence:.0%}*
"""

        return DynamicEvidenceResult(
            answer=formatted,
            refined_answer=refined,
            judge_result=judge_result,
            evidence_report=evidence_report,
            enriched_context=enriched_context,
            used_fulltext=enriched_context.fetched_count > 0,
            used_summarizer=False
        )

    def _build_simple_prompt(
        self,
        question: str,
        physics_knowledge: str,
        enriched_context: EnrichedContext
    ) -> str:
        """
        CQO í”„ë¡¬í”„íŠ¸ êµ¬ì„± (Phase 1: Lost in the Prompt Order ì ìš©)

        CQO = Context â†’ Question â†’ Options
        - Context: ëª¨ë“  ì°¸ì¡° ì •ë³´ë¥¼ ë¨¼ì € ì œì‹œ (decoder-only LLMì´ ë” ì˜ í™œìš©)
        - Question: ì»¨í…ìŠ¤íŠ¸ ì§í›„ ëª…í™•íˆ ì œì‹œ
        - Options: ì¶œë ¥ í˜•ì‹ ì§€ì‹œëŠ” ìµœì†Œí™”í•˜ì—¬ ë§ˆì§€ë§‰ì—

        ë…¼ë¬¸ ê·¼ê±°: "Lost in the Prompt Order" (2026) - CQO ìˆœì„œê°€
        QCO, OQC ëŒ€ë¹„ +14.7% ì •í™•ë„ í–¥ìƒ (decoder-only LLM ê¸°ì¤€)
        """
        prompt_parts = []

        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # [C] CONTEXT: ëª¨ë“  ì°¸ì¡° ì •ë³´ (ì—­í•  + ì§€ì‹ + ë¬¸í—Œ)
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

        # ì—­í•  ì •ì˜ (Contextì˜ ì¼ë¶€ë¡œ í¬í•¨)
        prompt_parts.append(
            "â•â•â• ë§¥ë½ ì •ë³´ â•â•â•\n\n"
            "ì—­í• : ìœ ë°©ì˜ìƒì˜í•™ ë¬¼ë¦¬í•™ ì „ë¬¸ê°€"
        )

        # ë¬¼ë¦¬í•™ ì§€ì‹ (í•µì‹¬ ì»¨í…ìŠ¤íŠ¸)
        if physics_knowledge:
            knowledge_excerpt = physics_knowledge[:4000]
            prompt_parts.append(f"\n\n[í‘œì¤€ ë¬¼ë¦¬í•™ ì°¸ì¡°]\n{knowledge_excerpt}")

        # ë…¼ë¬¸/ë¬¸í—Œ ì»¨í…ìŠ¤íŠ¸
        if enriched_context.enriched_context and len(enriched_context.enriched_context) > 100:
            context_excerpt = enriched_context.enriched_context[:2000]
            prompt_parts.append(f"\n\n[ê´€ë ¨ ë¬¸í—Œ]\n{context_excerpt}")

        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # [Q] QUESTION: ì»¨í…ìŠ¤íŠ¸ ì§í›„ ëª…í™•íˆ ì œì‹œ
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        prompt_parts.append(f"\n\nâ•â•â• ì§ˆë¬¸ â•â•â•\n\n{question}")

        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # [O] OPTIONS: ì¶œë ¥ ì§€ì‹œ (ìµœì†Œí™”)
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        prompt_parts.append(
            "\n\nâ•â•â• ë‹µë³€ í˜•ì‹ â•â•â•\n"
            "- ë¬¼ë¦¬ ì›ë¦¬ ê¸°ë°˜ ì„¤ëª…\n"
            "- í•„ìš”ì‹œ ê³„ì‚° ê³¼ì • í¬í•¨\n"
            "- í•œêµ­ì–´, ìì—°ìŠ¤ëŸ¬ìš´ ë¬¸ë‹¨"
        )

        return "\n".join(prompt_parts)

    def _build_qoco_prompt(
        self,
        question: str,
        physics_knowledge: str,
        enriched_context: EnrichedContext
    ) -> str:
        """
        QOCO í”„ë¡¬í”„íŠ¸ êµ¬ì„± (Phase 1 ëŒ€ì•ˆ)

        QOCO = Question-framing â†’ Options â†’ Context â†’ Output
        - ì§ˆë¬¸ ì˜ë„ë¥¼ ë¨¼ì € ëª…í™•íˆ â†’ ì–´ë–¤ ì •ë³´ê°€ í•„ìš”í•œì§€ í”„ë ˆì´ë°
        - ì˜µì…˜/ì œì•½ì¡°ê±´ ì œì‹œ
        - ê·¸ ë‹¤ìŒ ì»¨í…ìŠ¤íŠ¸ (ì§ˆë¬¸ ì˜ë„ë¥¼ ì•Œê³  ì½ìŒ)
        - ë§ˆì§€ë§‰ì— ì¶œë ¥ í˜•ì‹

        ì‚¬ìš© ì¼€ì´ìŠ¤: ê³„ì‚°/ë¹„êµ ì§ˆë¬¸ (ëª…í™•í•œ ë‹µ í˜•ì‹ì´ í•„ìš”í•œ ê²½ìš°)
        """
        prompt_parts = []

        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # [Q] QUESTION FRAMING: ì§ˆë¬¸ ì˜ë„ ëª…í™•í™”
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        prompt_parts.append(
            f"â•â•â• ì§ˆë¬¸ â•â•â•\n\n"
            f"ë‹¤ìŒ ìœ ë°©ì˜ìƒì˜í•™ ë¬¼ë¦¬í•™ ì§ˆë¬¸ì— ë‹µë³€í•˜ì‹œì˜¤:\n\n{question}"
        )

        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # [O] OPTIONS: ë‹µë³€ ì œì•½ì¡°ê±´
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        prompt_parts.append(
            "\n\nâ•â•â• ìš”êµ¬ì‚¬í•­ â•â•â•\n"
            "- ë¬¼ë¦¬ ê³µì‹ê³¼ ì›ë¦¬ ê¸°ë°˜ìœ¼ë¡œ ì„¤ëª…\n"
            "- ìˆ˜ì¹˜ ê³„ì‚° ì‹œ ë‹¨ê³„ë³„ ê³¼ì • ì œì‹œ\n"
            "- ì°¸ì¡° ì§€ì‹ê³¼ ì¼ê´€ì„± ìœ ì§€"
        )

        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # [C] CONTEXT: ì°¸ì¡° ì •ë³´
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        if physics_knowledge:
            knowledge_excerpt = physics_knowledge[:4000]
            prompt_parts.append(f"\n\nâ•â•â• ì°¸ì¡° ì§€ì‹ â•â•â•\n{knowledge_excerpt}")

        if enriched_context.enriched_context and len(enriched_context.enriched_context) > 100:
            context_excerpt = enriched_context.enriched_context[:2000]
            prompt_parts.append(f"\n\nâ•â•â• ê´€ë ¨ ë¬¸í—Œ â•â•â•\n{context_excerpt}")

        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # [O] OUTPUT: ì¶œë ¥ í˜•ì‹
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        prompt_parts.append(
            "\n\nâ•â•â• ë‹µë³€ â•â•â•\n"
            "í•œêµ­ì–´ë¡œ ëª…í™•í•˜ê²Œ ë‹µë³€:"
        )

        return "\n".join(prompt_parts)

    def _select_prompt_strategy(self, question: str) -> str:
        """
        ì§ˆë¬¸ ìœ í˜•ì— ë”°ë¥¸ í”„ë¡¬í”„íŠ¸ ì „ëµ ì„ íƒ (Phase 1)

        CQO: ê°œë… ì„¤ëª…, ì›ë¦¬ ì§ˆë¬¸ (ì»¨í…ìŠ¤íŠ¸ ì´í•´ê°€ ì¤‘ìš”)
        QOCO: ê³„ì‚°, ë¹„êµ, ìˆ˜ì¹˜ ì§ˆë¬¸ (ëª…í™•í•œ ë‹µ í˜•ì‹ í•„ìš”)

        Returns: "cqo" or "qoco"
        """
        # ê³„ì‚°/ìˆ˜ì¹˜ í‚¤ì›Œë“œ
        calculation_keywords = [
            "ê³„ì‚°", "êµ¬í•˜", "ì–¼ë§ˆ", "ëª‡", "%", "ë°°",
            "ë¹„êµ", "ì°¨ì´", "vs", "ëŒ€ë¹„",
            "ê³µì‹", "ìˆ˜ì¹˜", "ê°’"
        ]

        # ê°œë…/ì›ë¦¬ í‚¤ì›Œë“œ
        concept_keywords = [
            "ì™œ", "ì–´ë–»ê²Œ", "ì›ë¦¬", "ë©”ì»¤ë‹ˆì¦˜", "ì´ìœ ",
            "ì„¤ëª…", "ì˜ë¯¸", "ì˜í–¥", "ê´€ê³„"
        ]

        question_lower = question.lower()

        calc_score = sum(1 for kw in calculation_keywords if kw in question_lower)
        concept_score = sum(1 for kw in concept_keywords if kw in question_lower)

        # ê³„ì‚° ì§ˆë¬¸ì´ë©´ QOCO, ì•„ë‹ˆë©´ CQO (ê¸°ë³¸)
        if calc_score > concept_score and calc_score >= 2:
            return "qoco"
        return "cqo"

    def _simple_postprocess(self, text: str) -> str:
        """ìµœì†Œ í›„ì²˜ë¦¬"""
        import re

        # ì¤‘êµ­ì–´ ì œê±°
        chinese_map = {
            "å…¶ä¸­": "ì—¬ê¸°ì„œ", "æ›´é«˜çš„": "ë” ë†’ì€", "å› æ­¤": "ë”°ë¼ì„œ",
            "å¯ä»¥": "í•  ìˆ˜ ìˆë‹¤", "é€šè¿‡": "í†µí•´", "éœ€è¦": "í•„ìš”í•˜ë‹¤"
        }
        for ch, ko in chinese_map.items():
            text = text.replace(ch, ko)

        # <think> íƒœê·¸ ì œê±°
        text = re.sub(r'<think>.*?</think>', '', text, flags=re.DOTALL)

        return text.strip()

    # =========================================================================
    # Phase 7.6: Agentic Decomposition (Legacy)
    # =========================================================================

    async def process_with_decomposition_async(
        self,
        question: str,
        papers: List[Dict[str, Any]],
        physics_knowledge: str = "",
        max_pmc_fetch: int = 3
    ) -> DynamicEvidenceResult:
        """
        ë³µí•© ì§ˆë¬¸ ë¶„í•´ ê¸°ë°˜ ì²˜ë¦¬ (Phase 7.6)

        ë³µì¡í•œ ì§ˆë¬¸ì„ í•˜ìœ„ ì‘ì—…ìœ¼ë¡œ ë¶„í•´í•˜ì—¬ ê°ê° ì²˜ë¦¬ í›„ í•©ì„±í•©ë‹ˆë‹¤.
        ë‹¨ìˆœ ì§ˆë¬¸ì€ ê¸°ì¡´ process_asyncì™€ ë™ì¼í•˜ê²Œ ì²˜ë¦¬ë©ë‹ˆë‹¤.

        Args:
            question: ì‚¬ìš©ì ì§ˆë¬¸
            papers: ê²€ìƒ‰ëœ ë…¼ë¬¸ ëª©ë¡
            physics_knowledge: KnowledgeManager ì§€ì‹
            max_pmc_fetch: ìµœëŒ€ PMC ì¸ì¶œ ìˆ˜

        Returns:
            DynamicEvidenceResult
        """
        if not self.orchestrator:
            # ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„° ë¹„í™œì„±í™” ì‹œ ê¸°ì¡´ ë°©ì‹
            return await self.process_async(question, papers, physics_knowledge, max_pmc_fetch)

        logger.info(f"Processing with decomposition: {question[:50]}...")

        # 1. ì§ˆë¬¸ ë¶„í•´
        from src.reasoning.planner import DecompositionResult
        decomposition = self.orchestrator.planner.decompose(question)

        # ë‹¨ìˆœ ì§ˆë¬¸ì´ë©´ ê¸°ì¡´ ë°©ì‹ìœ¼ë¡œ
        if not decomposition.is_complex or len(decomposition.subtasks) <= 1:
            logger.info("Simple query - using standard pipeline")
            return await self.process_async(question, papers, physics_knowledge, max_pmc_fetch)

        logger.info(f"Complex query - decomposed into {len(decomposition.subtasks)} subtasks")

        # 2. PMC ì»¨í…ìŠ¤íŠ¸ ì¸ì¶œ (ì „ì²´ ì§ˆë¬¸ ê¸°ì¤€ - í•œ ë²ˆë§Œ)
        enriched_context = await self._enrich_context_async(question, papers, max_pmc_fetch)
        combined_context = self._build_combined_context(enriched_context, physics_knowledge)

        # 3. ê° subtask ê°œë³„ ì²˜ë¦¬
        for task in decomposition.subtasks:
            logger.info(f"Processing subtask {task.id}: {task.type.value} - {task.query[:50]}...")

            # subtaskë³„ ì§€ì‹ ëª¨ë“ˆ ë¡œë“œ
            task_knowledge = self.orchestrator._get_task_knowledge(task)

            try:
                result = self.reasoning_engine.reason(
                    question=task.query,
                    context=combined_context,
                    physics_knowledge=task_knowledge or physics_knowledge,
                    require_derivation=(task.type.value == "MATH")
                )
                task.answer = result.content
                task.confidence = result.final_confidence
                logger.info(f"Subtask {task.id} done: confidence={result.final_confidence:.0%}")

            except Exception as e:
                logger.error(f"Subtask {task.id} failed: {e}")
                task.answer = f"ë¶„ì„ ì‹¤íŒ¨: {str(e)}"
                task.confidence = 0.0

        # 4. ê²°ê³¼ í•©ì„±
        synthesis_report = self.orchestrator.synthesizer.synthesize(decomposition)

        # 5. í•©ì„±ëœ ë‹µë³€ìœ¼ë¡œ í‰ê°€ (ì²« ë²ˆì§¸ subtask ê¸°ì¤€)
        first_task = decomposition.subtasks[0]
        judge_result = self.judge.evaluate(
            question=question,
            answer=synthesis_report.content,
            derivation=first_task.answer,
            reference_knowledge=physics_knowledge,
            context=combined_context[:3000]
        )

        # 6. Evidence Mapping
        all_sources = self._build_source_list(papers, enriched_context.pmc_articles)
        evidence_report = self.evidence_mapper.analyze_answer(
            synthesis_report.content, all_sources
        )

        # 7. ìµœì¢… ê²°ê³¼ ë°˜í™˜ (í•©ì„±ëœ ë‹µë³€ ì‚¬ìš©)
        # RefinedAnswer ê°ì²´ ìƒì„± (í•©ì„± ê²°ê³¼ ê¸°ë°˜)
        from src.reasoning.text_logic import RefinedAnswer, AnswerQuality
        synthesized_refined = RefinedAnswer(
            content=synthesis_report.content,
            derivation=first_task.answer if first_task else "",
            evidence_mapping=[],
            recommendation="",
            quality=AnswerQuality.GOOD if synthesis_report.total_confidence >= 0.7 else AnswerQuality.NEEDS_REVISION,
            corrections_made=[],
            final_confidence=synthesis_report.total_confidence,
            clinical_insight=""
        )

        return DynamicEvidenceResult(
            answer=synthesis_report.content,
            refined_answer=synthesized_refined,
            judge_result=judge_result,
            evidence_report=evidence_report,
            enriched_context=enriched_context,
            used_fulltext=enriched_context.fetched_count > 0,
            used_summarizer=enriched_context.used_summarizer
        )

    # =========================================================================
    # Context Enrichment
    # =========================================================================

    async def _enrich_context_async(
        self,
        question: str,
        papers: List[Dict[str, Any]],
        max_fetch: int
    ) -> EnrichedContext:
        """PMC ì „ë¬¸ìœ¼ë¡œ ì»¨í…ìŠ¤íŠ¸ ê°•í™”"""

        # PMC IDê°€ ìˆëŠ” ë…¼ë¬¸ ì„ ë³„
        pmc_papers = [
            p for p in papers
            if p.get("pmc_id") and not p.get("pmc_id", "").startswith("None")
        ][:max_fetch]

        pmc_ids = [p["pmc_id"] for p in pmc_papers]

        # ì›ë³¸ ì»¨í…ìŠ¤íŠ¸ (ì´ˆë¡)
        original_context = self._build_abstract_context(papers)

        if not pmc_ids:
            return EnrichedContext(
                original_context=original_context,
                enriched_context=original_context,
                pmc_articles=[],
                fetched_count=0,
                total_chars=len(original_context),
                used_fulltext=False,
                used_summarizer=False
            )

        # ë¹„ë™ê¸° PMC ì¸ì¶œ
        logger.info(f"Fetching {len(pmc_ids)} PMC articles...")
        articles = await self.pmc_fetcher.fetch_multiple_async(pmc_ids)

        # ì§ˆë¬¸ ê´€ë ¨ ì»¨í…ìŠ¤íŠ¸ ì¶”ì¶œ + SLM ìš”ì•½ (Phase 7.1)
        enriched_parts = [original_context]
        summarizer_used = False

        for article in articles:
            # 1ë‹¨ê³„: ê¸°ì¡´ ë°©ì‹ìœ¼ë¡œ ê´€ë ¨ ì„¹ì…˜ ì¶”ì¶œ
            relevant_context = self.pmc_fetcher.extract_relevant_context(
                article, question, max_chars=6000  # ìš”ì•½ ì „ì´ë¯€ë¡œ ë” í° ì²­í¬ í—ˆìš©
            )

            if relevant_context:
                # 2ë‹¨ê³„: SLM ìš”ì•½ ë ˆì´ì–´ (Phase 7.1 í•µì‹¬)
                if self.use_summarizer and self.summarizer and len(relevant_context) > 1500:
                    logger.info(f"Summarizing {article.pmc_id}: {len(relevant_context):,} chars")
                    summary_result = self.summarizer.summarize(
                        full_text=relevant_context,
                        question=question,
                        pmc_id=article.pmc_id
                    )
                    # ìš”ì•½ëœ í…ìŠ¤íŠ¸ ì‚¬ìš©
                    final_context = summary_result.summary
                    summarizer_used = True
                    logger.info(f"Summarized {article.pmc_id}: {len(relevant_context):,} â†’ {len(final_context):,} chars ({summary_result.compression_ratio:.1%})")
                else:
                    # ì§§ê±°ë‚˜ ìš”ì•½ ë¹„í™œì„±í™” ì‹œ ì›ë³¸ ì‚¬ìš©
                    final_context = relevant_context

                enriched_parts.append(
                    f"\n\n[PMC ì „ë¬¸: {article.pmc_id}]\n{final_context}"
                )

        enriched_context = "\n".join(enriched_parts)

        return EnrichedContext(
            original_context=original_context,
            enriched_context=enriched_context,
            pmc_articles=articles,
            fetched_count=len(articles),
            total_chars=len(enriched_context),
            used_fulltext=len(articles) > 0,
            used_summarizer=summarizer_used
        )

    def _build_abstract_context(self, papers: List[Dict]) -> str:
        """ì´ˆë¡ ê¸°ë°˜ ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±"""
        parts = []
        for i, paper in enumerate(papers[:5], 1):
            abstract = paper.get("abstract", "")[:1500]
            title = paper.get("title", "Unknown")
            parts.append(f"[{i}] {title}\n{abstract}")
        return "\n\n".join(parts)

    def _build_combined_context(
        self,
        enriched: EnrichedContext,
        physics_knowledge: str
    ) -> str:
        """í†µí•© ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±"""
        parts = []

        if physics_knowledge:
            parts.append(f"### í‘œì¤€ ì°¸ì¡° ìë£Œ\n{physics_knowledge}")

        parts.append(f"### ê²€ìƒ‰ëœ ë¬¸ì„œ\n{enriched.enriched_context}")

        return "\n\n".join(parts)

    # =========================================================================
    # Source Building
    # =========================================================================

    def _build_source_list(
        self,
        papers: List[Dict],
        pmc_articles: List[PMCArticle]
    ) -> List[Dict]:
        """Evidence Mapperìš© ì†ŒìŠ¤ ëª©ë¡ êµ¬ì„±"""
        sources = []

        # ë…¼ë¬¸ (ì´ˆë¡)
        for paper in papers:
            sources.append({
                "id": paper.get("pmid", ""),
                "pmc_id": paper.get("pmc_id"),
                "title": paper.get("title", ""),
                "text": paper.get("abstract", ""),
                "has_fulltext": paper.get("pmc_id") is not None
            })

        # PMC ì „ë¬¸
        for article in pmc_articles:
            sources.append({
                "id": article.pmc_id,
                "pmc_id": article.pmc_id,
                "title": article.title,
                "text": article.results + " " + article.discussion,
                "section": "Results/Discussion",
                "has_fulltext": True
            })

        return sources

    # =========================================================================
    # Output Formatting
    # =========================================================================

    def _format_final_answer(
        self,
        refined: RefinedAnswer,
        evidence_report: EvidenceReport,
        used_fulltext: bool
    ) -> str:
        """ìµœì¢… ë‹µë³€ í¬ë§·íŒ…"""
        parts = []

        # ì „ë¬¸ ì‚¬ìš© ì•Œë¦¼
        if used_fulltext:
            parts.append("ğŸ’¡ **PMC ì „ë¬¸ ë¶„ì„ ì™„ë£Œ**: ì´ˆë¡ì— ì—†ëŠ” ìƒì„¸ ì •ë³´ê°€ í¬í•¨ë˜ì—ˆìŠµë‹ˆë‹¤.\n")

        # Phase 6 êµ¬ì¡°í™” ì¶œë ¥
        parts.append(self.reasoning_engine.format_structured_output(refined))

        # ê·¼ê±° ì¸ìš© (ê²€ì¦ëœ ê²ƒë§Œ)
        verified_claims = [mc for mc in evidence_report.mapped_claims if mc.is_verified]
        if verified_claims:
            parts.append("\n" + self.evidence_mapper.format_citations(verified_claims))

        return "\n".join(parts)


# =============================================================================
# Singleton
# =============================================================================

_pipeline_instance: Optional[DynamicEvidencePipeline] = None


def get_dynamic_evidence_pipeline() -> DynamicEvidencePipeline:
    """DynamicEvidencePipeline ì‹±ê¸€í†¤"""
    global _pipeline_instance
    if _pipeline_instance is None:
        _pipeline_instance = DynamicEvidencePipeline()
    return _pipeline_instance


# =============================================================================
# Test
# =============================================================================

if __name__ == "__main__":
    import asyncio
    logging.basicConfig(level=logging.INFO)

    async def test():
        pipeline = DynamicEvidencePipeline()

        # í…ŒìŠ¤íŠ¸ ë…¼ë¬¸ (ì‹¤ì œ PMC ID)
        test_papers = [
            {
                "pmid": "32478901",
                "pmc_id": "PMC7533093",
                "title": "Digital Mammography Optimization",
                "abstract": "This study examines the optimization of digital mammography..."
            }
        ]

        test_knowledge = """
SNR âˆ âˆšDose ê´€ê³„ì— ì˜í•´:
- SNRì„ 2ë°°ë¡œ ë†’ì´ë ¤ë©´ ì„ ëŸ‰ì„ 4ë°°ë¡œ ì¦ê°€
"""

        question = "ë””ì§€í„¸ ìœ ë°©ì´¬ì˜ì—ì„œ í™”ì§ˆê³¼ ì„ ëŸ‰ì˜ ê´€ê³„ëŠ”?"

        print("=" * 60)
        print("Dynamic Evidence Pipeline Test")
        print("=" * 60)
        print(f"ì§ˆë¬¸: {question}")
        print("-" * 60)

        result = await pipeline.process_async(
            question=question,
            papers=test_papers,
            physics_knowledge=test_knowledge,
            max_pmc_fetch=1
        )

        print(f"\nì „ë¬¸ ì‚¬ìš©: {result.used_fulltext}")
        print(f"ì¸ì¶œëœ PMC: {result.enriched_context.fetched_count}ê°œ")
        print(f"í’ˆì§ˆ ì ìˆ˜: {result.judge_result.total_score:.0f}/100")
        print(f"ê²€ì¦ëœ ì£¼ì¥: {result.evidence_report.verified_claims}/{result.evidence_report.total_claims}")
        print()
        print(result.answer[:1500] + "..." if len(result.answer) > 1500 else result.answer)

    asyncio.run(test())
