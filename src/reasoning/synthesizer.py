"""
Sophia AI: Response Synthesizer (Phase 7.6)
===========================================
ë¶„í•´ëœ í•˜ìœ„ ë‹µë³€ë“¤ì„ í†µí•©í•˜ì—¬ ìµœì¢… ë³´ê³ ì„œ ìƒì„±

Executorë“¤ì´ ìƒì„±í•œ ê°œë³„ ë‹µë³€ì„ ìˆ˜ì§‘í•˜ì—¬:
1. ë…¼ë¦¬ì  ì¼ê´€ì„± ê²€í† 
2. ì¤‘ë³µ ì œê±° ë° ì •ë¦¬
3. êµ¬ì¡°í™”ëœ LaTeX ë³´ê³ ì„œë¡œ í•©ì„±
"""

import json
import logging
import re
from dataclasses import dataclass
from typing import List, Optional
import requests

from src.reasoning.planner import SubTask, TaskType, DecompositionResult

logger = logging.getLogger(__name__)


@dataclass
class SynthesizerConfig:
    """í•©ì„±ê¸° ì„¤ì •"""
    ollama_url: str = "http://localhost:11434"
    synthesizer_model: str = "glm4:9b"  # ê°€ë²¼ìš´ ëª¨ë¸ë¡œ í•©ì„±
    timeout: int = 90
    max_answer_length: int = 3000


@dataclass
class SynthesizedReport:
    """í•©ì„±ëœ ìµœì¢… ë³´ê³ ì„œ"""
    content: str  # ì „ì²´ ë‹µë³€
    sections: List[dict]  # ì„¹ì…˜ë³„ ë‚´ìš©
    total_confidence: float
    synthesis_notes: str = ""


class ResponseSynthesizer:
    """
    ì‘ë‹µ í•©ì„±ê¸°

    ë¶„í•´ëœ í•˜ìœ„ ì‘ì—…ì˜ ë‹µë³€ë“¤ì„ ëª¨ì•„ í•˜ë‚˜ì˜ ì™„ì„±ëœ ë³´ê³ ì„œë¡œ í†µí•©í•©ë‹ˆë‹¤.
    """

    SYSTEM_PROMPT = r"""ë‹¹ì‹ ì€ ì˜í•™ ë¬¼ë¦¬ ì „ë¬¸ ë³´ê³ ì„œ ì‘ì„±ìì…ë‹ˆë‹¤.
ì—¬ëŸ¬ í•˜ìœ„ ë¶„ì„ ê²°ê³¼ë¥¼ ë°›ì•„ í•˜ë‚˜ì˜ ì™„ì„±ëœ ì „ë¬¸ê°€ ë³´ê³ ì„œë¡œ í•©ì„±í•˜ì‹­ì‹œì˜¤.

## ğŸ“‹ í•©ì„± ê·œì¹™:
1. **êµ¬ì¡°í™”**: ê° í•˜ìœ„ ë‹µë³€ì„ ë…¼ë¦¬ì  ìˆœì„œë¡œ ë°°ì¹˜
2. **ì—°ê²°ì„±**: ì„¹ì…˜ ê°„ ìì—°ìŠ¤ëŸ¬ìš´ ì „í™˜ ë¬¸êµ¬ ì¶”ê°€
3. **ì¤‘ë³µ ì œê±°**: ë™ì¼í•œ ë‚´ìš©ì´ ë°˜ë³µë˜ë©´ í•œ ë²ˆë§Œ ê¸°ìˆ 
4. **ìˆ˜ì‹ ë³´ì¡´**: LaTeX ìˆ˜ì‹ì€ ì ˆëŒ€ ìˆ˜ì •í•˜ì§€ ì•Šê³  ê·¸ëŒ€ë¡œ ìœ ì§€

## ğŸ“¤ ì¶œë ¥ í˜•ì‹:

### ğŸ“ 1. [ì²« ë²ˆì§¸ ë¶„ì„ ì œëª©]
[ì²« ë²ˆì§¸ í•˜ìœ„ ë‹µë³€ ë‚´ìš©]

### ğŸ”¬ 2. [ë‘ ë²ˆì§¸ ë¶„ì„ ì œëª©]
[ë‘ ë²ˆì§¸ í•˜ìœ„ ë‹µë³€ ë‚´ìš©]

### ğŸ“š 3. [ì„¸ ë²ˆì§¸ ë¶„ì„ ì œëª©]
[ì„¸ ë²ˆì§¸ í•˜ìœ„ ë‹µë³€ ë‚´ìš©]

### ğŸ’¡ ì¢…í•© ê²°ë¡ 
[ì „ì²´ ë¶„ì„ì„ ì¢…í•©í•œ ìµœì¢… ê²°ë¡ ]

---
ğŸ† **ê²€ì¦ ì™„ë£Œ** (ì¢…í•© ì‹ ë¢°ë„: XX%)

## âš ï¸ ì£¼ì˜ì‚¬í•­:
- ìˆ˜ì‹($...$, $$...$$)ì€ ì ˆëŒ€ ë³€ê²½ ê¸ˆì§€
- ê° ì„¹ì…˜ì˜ í•µì‹¬ ìˆ˜ì¹˜ì™€ ê²°ë¡ ì€ ë°˜ë“œì‹œ í¬í•¨
- í•œêµ­ì–´ë¡œ ì‘ì„±"""

    SECTION_ICONS = {
        TaskType.MATH: "ğŸ“",
        TaskType.CONCEPT: "ğŸ”¬",
        TaskType.SEARCH: "ğŸ“š",
    }

    SECTION_TITLES = {
        TaskType.MATH: "ìˆ˜ì‹ ì¦ëª…",
        TaskType.CONCEPT: "ë¬¼ë¦¬ì  ë¶„ì„",
        TaskType.SEARCH: "ë¬¸í—Œ ê·¼ê±°",
    }

    def __init__(self, config: Optional[SynthesizerConfig] = None):
        self.config = config or SynthesizerConfig()

    def synthesize(self, decomposition: DecompositionResult) -> SynthesizedReport:
        """
        í•˜ìœ„ ë‹µë³€ë“¤ì„ í•©ì„±í•˜ì—¬ ìµœì¢… ë³´ê³ ì„œ ìƒì„±

        Args:
            decomposition: í•˜ìœ„ ì‘ì—…ë“¤ (ë‹µë³€ í¬í•¨)

        Returns:
            SynthesizedReport: í•©ì„±ëœ ë³´ê³ ì„œ
        """
        subtasks = decomposition.subtasks

        # ë‹µë³€ì´ ìˆëŠ” subtaskë§Œ í•„í„°ë§
        completed_tasks = [t for t in subtasks if t.answer]

        if not completed_tasks:
            logger.warning("No completed subtasks to synthesize")
            return SynthesizedReport(
                content="ë¶„ì„ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.",
                sections=[],
                total_confidence=0.0,
                synthesis_notes="í•˜ìœ„ ì‘ì—… ë‹µë³€ ì—†ìŒ"
            )

        logger.info(f"Synthesizing {len(completed_tasks)} subtask answers...")

        # ë‹¨ì¼ ë‹µë³€ì´ë©´ í•©ì„± ì—†ì´ í¬ë§·íŒ…ë§Œ
        if len(completed_tasks) == 1:
            return self._format_single_answer(completed_tasks[0])

        # ë³µìˆ˜ ë‹µë³€ í•©ì„±
        return self._synthesize_multiple(completed_tasks, decomposition.original_query)

    def _format_single_answer(self, task: SubTask) -> SynthesizedReport:
        """ë‹¨ì¼ ë‹µë³€ í¬ë§·íŒ…"""
        icon = self.SECTION_ICONS.get(task.type, "ğŸ“")
        title = self.SECTION_TITLES.get(task.type, "ë¶„ì„")

        content = f"### {icon} {title}\n\n{task.answer}\n\n"
        content += f"---\nâœ… **ì™„ë£Œ** (ì‹ ë¢°ë„: {task.confidence:.0%})"

        return SynthesizedReport(
            content=content,
            sections=[{
                "type": task.type.value,
                "title": title,
                "content": task.answer,
                "confidence": task.confidence
            }],
            total_confidence=task.confidence,
            synthesis_notes="ë‹¨ì¼ ë¶„ì„"
        )

    def _synthesize_multiple(self, tasks: List[SubTask], original_query: str) -> SynthesizedReport:
        """ë³µìˆ˜ ë‹µë³€ í•©ì„±"""

        # 1. ê·œì¹™ ê¸°ë°˜ í•©ì„± ì‹œë„ (LLM ì—†ì´)
        sections = []
        content_parts = []

        for i, task in enumerate(tasks, 1):
            icon = self.SECTION_ICONS.get(task.type, "ğŸ“")
            title = self.SECTION_TITLES.get(task.type, "ë¶„ì„")

            section_content = f"### {icon} {i}. {title}\n\n{task.answer}"
            content_parts.append(section_content)

            sections.append({
                "type": task.type.value,
                "title": title,
                "content": task.answer,
                "confidence": task.confidence
            })

        # 2. ì¢…í•© ê²°ë¡  ìƒì„±
        avg_confidence = sum(t.confidence for t in tasks) / len(tasks)
        conclusion = self._generate_conclusion(tasks, avg_confidence)

        content_parts.append(f"\n### ğŸ’¡ ì¢…í•© ê²°ë¡ \n\n{conclusion}")

        # 3. ìµœì¢… ì‹ ë¢°ë„ ë°°ì§€
        if avg_confidence >= 0.9:
            badge = "ğŸ† **ê²€ì¦ ì™„ë£Œ**"
        elif avg_confidence >= 0.7:
            badge = "âœ… **ì–‘í˜¸**"
        else:
            badge = "âš ï¸ **ì£¼ì˜ í•„ìš”**"

        content_parts.append(f"\n---\n{badge} (ì¢…í•© ì‹ ë¢°ë„: {avg_confidence:.0%})")

        final_content = "\n\n".join(content_parts)

        return SynthesizedReport(
            content=final_content,
            sections=sections,
            total_confidence=avg_confidence,
            synthesis_notes=f"{len(tasks)}ê°œ ë¶„ì„ í†µí•©"
        )

    def _generate_conclusion(self, tasks: List[SubTask], confidence: float) -> str:
        """ì¢…í•© ê²°ë¡  ìƒì„±"""
        conclusions = []

        for task in tasks:
            if task.type == TaskType.MATH:
                # ìˆ˜í•™ ê²°ê³¼ì—ì„œ í•µì‹¬ ìˆ˜ì¹˜ ì¶”ì¶œ
                numbers = re.findall(r'\*\*(\d+(?:\.\d+)?%?)\*\*', task.answer)
                if numbers:
                    conclusions.append(f"ìˆ˜ì‹ ë¶„ì„ ê²°ê³¼: {', '.join(numbers[:2])}")

            elif task.type == TaskType.CONCEPT:
                conclusions.append("ë¬¼ë¦¬ì  ê¸°ì „ì´ ë¶„ì„ë˜ì—ˆìŠµë‹ˆë‹¤.")

            elif task.type == TaskType.SEARCH:
                conclusions.append("ê´€ë ¨ ë¬¸í—Œ ê·¼ê±°ê°€ í™•ë³´ë˜ì—ˆìŠµë‹ˆë‹¤.")

        if not conclusions:
            return "ëª¨ë“  í•˜ìœ„ ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤."

        return " ".join(conclusions)

    def synthesize_with_llm(self, decomposition: DecompositionResult) -> SynthesizedReport:
        """
        LLMì„ ì‚¬ìš©í•œ ê³ ê¸‰ í•©ì„± (ì„ íƒì )

        Args:
            decomposition: í•˜ìœ„ ì‘ì—…ë“¤ (ë‹µë³€ í¬í•¨)

        Returns:
            SynthesizedReport: í•©ì„±ëœ ë³´ê³ ì„œ
        """
        subtasks = decomposition.subtasks
        completed_tasks = [t for t in subtasks if t.answer]

        if not completed_tasks:
            return SynthesizedReport(
                content="ë¶„ì„ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.",
                sections=[],
                total_confidence=0.0
            )

        # LLM í”„ë¡¬í”„íŠ¸ êµ¬ì„±
        task_summaries = []
        for task in completed_tasks:
            task_summaries.append(f"""
[í•˜ìœ„ ë¶„ì„ {task.id}] ìœ í˜•: {task.type.value}
ì§ˆë¬¸: {task.query}
ë‹µë³€:
{task.answer}
ì‹ ë¢°ë„: {task.confidence:.0%}
""")

        user_prompt = f"""ì›ë³¸ ì§ˆë¬¸: {decomposition.original_query}

ë‹¤ìŒ í•˜ìœ„ ë¶„ì„ ê²°ê³¼ë“¤ì„ í•˜ë‚˜ì˜ ì™„ì„±ëœ ë³´ê³ ì„œë¡œ í•©ì„±í•˜ì„¸ìš”:

{''.join(task_summaries)}

ìœ„ ê²°ê³¼ë“¤ì„ í†µí•©í•˜ì—¬ ì „ë¬¸ê°€ ë³´ê³ ì„œë¥¼ ì‘ì„±í•˜ì„¸ìš”."""

        try:
            response = requests.post(
                f"{self.config.ollama_url}/api/chat",
                json={
                    "model": self.config.synthesizer_model,
                    "messages": [
                        {"role": "system", "content": self.SYSTEM_PROMPT},
                        {"role": "user", "content": user_prompt}
                    ],
                    "stream": False,
                    "options": {
                        "num_predict": 2000,
                        "temperature": 0.3,
                    }
                },
                timeout=self.config.timeout
            )

            response.raise_for_status()
            synthesized = response.json().get("message", {}).get("content", "")

            avg_confidence = sum(t.confidence for t in completed_tasks) / len(completed_tasks)

            return SynthesizedReport(
                content=synthesized,
                sections=[{"type": t.type.value, "content": t.answer} for t in completed_tasks],
                total_confidence=avg_confidence,
                synthesis_notes="LLM í•©ì„± ì™„ë£Œ"
            )

        except Exception as e:
            logger.error(f"LLM synthesis failed: {e}")
            # í´ë°±: ê·œì¹™ ê¸°ë°˜ í•©ì„±
            return self._synthesize_multiple(completed_tasks, decomposition.original_query)


# =============================================================================
# Singleton
# =============================================================================

_synthesizer_instance: Optional[ResponseSynthesizer] = None


def get_response_synthesizer() -> ResponseSynthesizer:
    """ResponseSynthesizer ì‹±ê¸€í†¤"""
    global _synthesizer_instance
    if _synthesizer_instance is None:
        _synthesizer_instance = ResponseSynthesizer()
    return _synthesizer_instance


# =============================================================================
# Test
# =============================================================================

if __name__ == "__main__":
    logging.basicConfig(level=logging.INFO)

    from src.reasoning.planner import DecompositionResult, SubTask, TaskType

    # í…ŒìŠ¤íŠ¸ ë°ì´í„°
    test_result = DecompositionResult(
        original_query="PCD vs EID ë³µí•© ì§ˆë¬¸",
        is_complex=True,
        subtasks=[
            SubTask(
                id=1,
                type=TaskType.MATH,
                query="SNR í•˜ë½í­ ê³„ì‚°",
                required_modules=["snr_cnr"],
                answer="ì„ ëŸ‰ 50% ê°ì†Œ ì‹œ SNRì€ $$\\sqrt{0.5} \\approx 0.707$$ë°°ë¡œ ê°ì†Œí•©ë‹ˆë‹¤. ì¦‰ **29.3%** í•˜ë½í•©ë‹ˆë‹¤.",
                confidence=0.95
            ),
            SubTask(
                id=2,
                type=TaskType.CONCEPT,
                query="PCDì˜ d' íšŒë³µ ê¸°ì „",
                required_modules=["detector_physics"],
                answer="PCDëŠ” ì—ë„ˆì§€ ë¬¸í„±ì¹˜ ì„¤ì •ìœ¼ë¡œ ì „ì ë…¸ì´ì¦ˆë¥¼ ë¬¼ë¦¬ì ìœ¼ë¡œ ì œê±°í•©ë‹ˆë‹¤. ì´ë¡œ ì¸í•´ $d'$ ì§€ìˆ˜ê°€ íšŒë³µë©ë‹ˆë‹¤.",
                confidence=0.88
            ),
            SubTask(
                id=3,
                type=TaskType.SEARCH,
                query="ìµœê·¼ PCD ë…¼ë¬¸",
                required_modules=["PMC"],
                answer="Day et al. (2024)ì˜ Monte-Carlo ì—°êµ¬ì—ì„œ CdTe PCDê°€ ëŒ€ì¡°ë„ë¥¼ **25%** í–¥ìƒì‹œì¼°ìŠµë‹ˆë‹¤.",
                confidence=0.75
            ),
        ],
        reasoning="ìˆ˜ì‹ ì¦ëª…, ê°œë… ì„¤ëª…, ë¬¸í—Œ ê²€ìƒ‰ì´ ëª¨ë‘ í•„ìš”"
    )

    synthesizer = ResponseSynthesizer()
    report = synthesizer.synthesize(test_result)

    print(f"\n{'='*60}")
    print("SYNTHESIZED REPORT")
    print(f"{'='*60}")
    print(report.content)
    print(f"\nTotal Confidence: {report.total_confidence:.0%}")
    print(f"Notes: {report.synthesis_notes}")
