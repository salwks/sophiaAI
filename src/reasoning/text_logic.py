"""
Clinical Text Excellence: Answering Twice Logic
================================================
ë³µì¡í•œ ì„ìƒ í…ìŠ¤íŠ¸ì— ëŒ€í•´ 2ë‹¨ê³„ ì¶”ë¡ ì„ ìˆ˜í–‰í•˜ì—¬ 99.9% ì •í™•ë„ë¥¼ ëª©í‘œë¡œ í•©ë‹ˆë‹¤.

Workflow:
    [Stage 1: Drafting]
    - ëª¨ë“  ê·¼ê±° ìë£Œ(ì§€ì‹ ëª¨ë“ˆ, ë…¼ë¬¸, ê°€ì´ë“œë¼ì¸)ë¥¼ í†µí•©
    - ê°€ì„¤ì  ë‹µë³€(Draft) ìƒì„±
    - ë³€ìˆ˜ ë‹¨ìœ„ë¡œ Golden Formula ëŒ€ì¡°

    [Stage 2: Refinement]
    - Self-Correction: ë…¼ë¦¬ì  í—ˆì  íƒì§€
    - BI-RADS ê°€ì´ë“œë¼ì¸ ìœ„ë°˜ ì—¬ë¶€ ê²€ì¦
    - ìµœì¢… ì •ì œëœ ë‹µë³€ ì¶œë ¥

Output Structure:
    1. Derivation (ì¦ëª… ê³¼ì •)
    2. Evidence Mapping (ê·¼ê±° ë§¤í•‘)
    3. Recommendation (ìµœì¢… ê¶Œê³ )
"""

import json
import re
import logging
from typing import Optional, Dict, Any, List, Tuple
from dataclasses import dataclass, field
from enum import Enum
import requests

logger = logging.getLogger(__name__)


class AnswerQuality(Enum):
    """ë‹µë³€ í’ˆì§ˆ ë“±ê¸‰"""
    EXCELLENT = "excellent"      # ì™„ë²½í•œ ê·¼ê±° ê¸°ë°˜, ë…¼ë¦¬ì  ì¼ê´€ì„±
    GOOD = "good"               # ëŒ€ë¶€ë¶„ ì •í™•, ì‚¬ì†Œí•œ ê°œì„  ê°€ëŠ¥
    NEEDS_REVISION = "needs_revision"  # ìˆ˜ì • í•„ìš”
    UNRELIABLE = "unreliable"   # ì‹ ë¢°í•  ìˆ˜ ì—†ìŒ, ì¬ìƒì„± í•„ìš”


@dataclass
class DraftAnswer:
    """1ë‹¨ê³„: ê°€ì„¤ì  ë‹µë³€"""
    content: str
    derivation: str                    # ì¦ëª…/ì¶”ë¡  ê³¼ì •
    evidence_citations: List[str]      # ì¸ìš©ëœ ê·¼ê±°
    formula_checks: List[Dict]         # ìˆ˜ì‹ ê²€ì¦ ê²°ê³¼
    confidence: float                  # ì‹ ë¢°ë„ (0-1)


@dataclass
class RefinedAnswer:
    """2ë‹¨ê³„: ì •ì œëœ ìµœì¢… ë‹µë³€"""
    content: str
    derivation: str                    # ì¦ëª… ê³¼ì •
    evidence_mapping: List[Dict]       # ê·¼ê±° ë§¤í•‘
    recommendation: str                # ìµœì¢… ê¶Œê³ 
    quality: AnswerQuality
    corrections_made: List[str]        # ìˆ˜ì • ì‚¬í•­
    final_confidence: float
    clinical_insight: str = ""         # Phase 7.2: ì„ìƒì  ì˜í–¥ ë¶„ì„ (FN/FP ê¸°ì „)


@dataclass
class TextReasoningConfig:
    """í…ìŠ¤íŠ¸ ì¶”ë¡  ì„¤ì • (Phase 7.4: ì‹¬ì¸µ ì¶”ë¡  ì§€ì›)"""
    ollama_url: str = "http://localhost:11434"
    reasoning_model: str = "gpt-oss:20b"             # Phase 7.10: GPT-OSS 20B (long-context í•©ì„± ìš°ìˆ˜)
    critic_model: str = "glm4:9b"            # ë¹ ë¥¸ ê²€ì¦ìš©
    draft_timeout: int = 600                     # Phase 7.4: 10ë¶„ (ë³µì¡í•œ ì¶”ë¡  ëŒ€ì‘)
    refine_timeout: int = 300                    # Phase 7.4: 5ë¶„ (ê²€ì¦ ë‹¨ê³„)
    min_confidence_threshold: float = 0.85
    max_refinement_iterations: int = 2


class TextReasoningEngine:
    """
    Answering Twice: 2ë‹¨ê³„ í…ìŠ¤íŠ¸ ì¶”ë¡  ì—”ì§„

    Usage:
        engine = TextReasoningEngine()
        result = engine.reason(
            question="DBTì—ì„œ 5cm ìœ ë°©ì˜ MGD ê³„ì‚° ì‹œ T-factor ê°’ì€?",
            context=context,
            physics_knowledge=knowledge
        )
    """

    def __init__(self, config: Optional[TextReasoningConfig] = None):
        self.config = config or TextReasoningConfig()

    # =========================================================================
    # Main Entry Point
    # =========================================================================

    def reason(
        self,
        question: str,
        context: str,
        physics_knowledge: str = "",
        require_derivation: bool = True
    ) -> RefinedAnswer:
        """
        2ë‹¨ê³„ ì¶”ë¡  ìˆ˜í–‰

        Args:
            question: ì‚¬ìš©ì ì§ˆë¬¸
            context: ê²€ìƒ‰ëœ ë¬¸ì„œ ì»¨í…ìŠ¤íŠ¸
            physics_knowledge: KnowledgeManager ì§€ì‹
            require_derivation: ì¦ëª… ê³¼ì • í•„ìˆ˜ ì—¬ë¶€

        Returns:
            RefinedAnswer: ì •ì œëœ ìµœì¢… ë‹µë³€
        """
        logger.info(f"Starting 2-stage reasoning for: {question[:50]}...")

        # Stage 1: Drafting
        draft = self._stage1_draft(
            question=question,
            context=context,
            physics_knowledge=physics_knowledge,
            require_derivation=require_derivation
        )

        logger.info(f"Draft confidence: {draft.confidence:.2f}")

        # Stage 2: Refinement (Self-Correction)
        refined = self._stage2_refine(
            question=question,
            draft=draft,
            physics_knowledge=physics_knowledge
        )

        logger.info(f"Final quality: {refined.quality.value}, confidence: {refined.final_confidence:.2f}")

        # Phase 7.13: í’ˆì§ˆ ê²€ì¦ ë° MTF-í˜•íƒœ ì—°ê²° í•„ìˆ˜ ê²€ì¦
        refined = self._validate_and_enhance_output(question, refined, physics_knowledge)

        return refined

    def _validate_and_enhance_output(
        self,
        question: str,
        result: RefinedAnswer,
        physics_knowledge: str
    ) -> RefinedAnswer:
        """
        Phase 7.13: ì¶œë ¥ í’ˆì§ˆ ê²€ì¦ ë° í•„ìˆ˜ ë‚´ìš© ë³´ê°•

        - í’ˆì§ˆ ì„ê³„ê°’ ë¯¸ë‹¬ ì‹œ ê²½ê³  ì¶”ê°€
        - MTF-í˜•íƒœ ì—°ê²° í•„ìˆ˜ ê²€ì¦ (Fine Linear/Amorphous ì§ˆë¬¸)
        - ì„ ëŸ‰-MTF ë¬´ê´€ì„± ì„¤ëª… ê²€ì¦
        """
        question_lower = question.lower()
        content = result.content

        # 1. MTF-í˜•íƒœ ì—°ê²° í•„ìˆ˜ ê²€ì¦ (Fine Linear, Amorphous, í˜•íƒœ, ë­‰ê°œ ë“± ì–¸ê¸‰ ì‹œ)
        is_morphology_question = any(kw in question_lower for kw in [
            'fine linear', 'amorphous', 'í˜•íƒœ', 'ë­‰ê°œ', 'morphology',
            '4c', '4b', 'bi-rads', 'ì„íšŒí™”'
        ])

        mtf_keywords = ['mtf', 'í•´ìƒë„', 'ê³ ì£¼íŒŒ', 'ê³µê°„ì£¼íŒŒìˆ˜', 'lp/mm', 'ë¹› í™•ì‚°', 'light spread']
        has_mtf_explanation = any(kw in content.lower() for kw in mtf_keywords)

        missing_explanations = []

        if is_morphology_question and not has_mtf_explanation:
            missing_explanations.append(
                "âš ï¸ **MTF-í˜•íƒœ ì—°ê²° ëˆ„ë½**: Fine Linear â†’ Amorphous í˜•íƒœ ë³€í™”ëŠ” "
                "**ê³ ì£¼íŒŒ MTF ì†ì‹¤** (MTF_system < 0.2 at 5 lp/mm)ì´ ì£¼ì›ì¸ì…ë‹ˆë‹¤. "
                "ë¹” ê²½í™” â†’ CsI ê¹Šì´ ì¹¨íˆ¬ â†’ ë¹› í™•ì‚° ì¦ê°€ â†’ MTF ì €í•˜ â†’ ê³ ì£¼íŒŒ ì†ì‹¤"
            )

        # 2. ì„ ëŸ‰-MTF/ëŒ€ì¡°ë„ ë¬´ê´€ì„± ê²€ì¦
        dose_keywords = ['ì„ ëŸ‰', 'dose', 'ë…¸ì¶œ']
        is_dose_question = any(kw in question_lower for kw in dose_keywords)

        if is_dose_question or is_morphology_question:
            dose_limitation_keywords = ['ì„ ëŸ‰.*ë¬´ê´€', 'dose.*independent', 'mtf.*ì„ ëŸ‰.*ë¬´ê´€',
                                        'ì„ ëŸ‰.*íšŒë³µ.*ë¶ˆê°€', 'ë…¸ì´ì¦ˆë§Œ', 'noise only']
            has_dose_limitation = any(re.search(kw, content.lower()) for kw in dose_limitation_keywords)

            if not has_dose_limitation and ('ì„ ëŸ‰' in question or 'dose' in question_lower):
                missing_explanations.append(
                    "âš ï¸ **ì„ ëŸ‰ í•œê³„ ì„¤ëª… ëˆ„ë½**: ì„ ëŸ‰ ì¦ê°€ëŠ” **ë…¸ì´ì¦ˆ(Ïƒ)ë§Œ ê°ì†Œ**ì‹œí‚¤ë©°, "
                    "MTF(ê³µê°„í•´ìƒë„)ì™€ Î”Î¼(í”¼ì‚¬ì²´ ëŒ€ì¡°ë„)ëŠ” ì„ ëŸ‰ê³¼ ë¬´ê´€í•©ë‹ˆë‹¤."
                )

        # 3. í’ˆì§ˆ ì„ê³„ê°’ ê²€ì¦
        if result.final_confidence < self.config.min_confidence_threshold:
            missing_explanations.append(
                f"âš ï¸ **ì‹ ë¢°ë„ ë‚®ìŒ** ({result.final_confidence:.0%} < {self.config.min_confidence_threshold:.0%}): "
                "ë‹µë³€ì˜ ì •í™•ì„±ì„ ì¬í™•ì¸í•˜ì„¸ìš”."
            )

        # 4. ëˆ„ë½ëœ ì„¤ëª…ì´ ìˆìœ¼ë©´ contentì— ì¶”ê°€
        if missing_explanations:
            enhancement_block = "\n\n---\n### ğŸ”¬ ë¬¼ë¦¬ ê²€ì¦ ë³´ê°• (Phase 7.13)\n" + "\n\n".join(missing_explanations)
            enhanced_content = content + enhancement_block

            # corrections_madeì—ë„ ì¶”ê°€
            new_corrections = list(result.corrections_made) + [
                f"Phase 7.13: {len(missing_explanations)}ê°œ í•„ìˆ˜ ì„¤ëª… ë³´ê°•"
            ]

            logger.warning(f"Phase 7.13: Added {len(missing_explanations)} missing explanations")

            return RefinedAnswer(
                content=enhanced_content,
                derivation=result.derivation,
                evidence_mapping=result.evidence_mapping,
                recommendation=result.recommendation,
                quality=result.quality,
                corrections_made=new_corrections,
                final_confidence=result.final_confidence,
                clinical_insight=result.clinical_insight
            )

        return result

    # =========================================================================
    # Stage 1: Drafting
    # =========================================================================

    def _stage1_draft(
        self,
        question: str,
        context: str,
        physics_knowledge: str,
        require_derivation: bool
    ) -> DraftAnswer:
        """
        1ë‹¨ê³„: ê°€ì„¤ì  ë‹µë³€ ìƒì„±

        - ëª¨ë“  ê·¼ê±° ìë£Œ í†µí•©
        - Golden Formula ë³€ìˆ˜ ëŒ€ì¡°
        - ì¦ëª… ê³¼ì • í¬í•¨
        """
        # Phase 7.14: ë‹¨ìˆœí™”ëœ í”„ë¡¬í”„íŠ¸ (JSON ì¶œë ¥ ì œê±°)
        system_prompt = """ë‹¹ì‹ ì€ ìœ ë°©ì˜ìƒì˜í•™ ë¬¼ë¦¬í•™ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. í•œêµ­ì–´ë¡œ ë‹µë³€í•˜ì„¸ìš”.

## í•„ìˆ˜ ê·œì¹™

1. **ì œê³µëœ "í‘œì¤€ ì°¸ì¡° ìë£Œ"ì˜ ê³µì‹ê³¼ ìˆ˜ì¹˜ë§Œ ì‚¬ìš©** - ê¸°ì–µì—ì„œ ëŒì–´ë‚´ì§€ ë§ ê²ƒ
2. **"âš ï¸ ê²½ê³ " ì„¹ì…˜ì˜ "âŒ í‹€ë¦¼" ë‚´ìš©ì€ ì ˆëŒ€ ì¶œë ¥ ê¸ˆì§€**
3. **ë¬¼ë¦¬ì  ê·¼ê±°ì™€ ê³„ì‚° ê³¼ì •ì„ ë°˜ë“œì‹œ í¬í•¨**

## í•µì‹¬ ë¬¼ë¦¬ ì˜¤ë¥˜ ë°©ì§€

ë‹¤ìŒì€ **ì ˆëŒ€ ì¶œë ¥ ê¸ˆì§€**:
- "ë¹” ê²½í™”ê°€ ëŒ€ì¡°ë„ë¥¼ í–¥ìƒì‹œí‚¨ë‹¤" âŒ â†’ ì •ë‹µ: ë¹” ê²½í™”ëŠ” ëŒ€ì¡°ë„ë¥¼ **ê°ì†Œ**ì‹œí‚´ (Î¼_pe âˆ 1/EÂ³)
- "K-edgeê°€ ëŒ€ì¡°ë„ ì†ì‹¤ì„ ë³´ìƒí•œë‹¤" âŒ â†’ ì •ë‹µ: K-edgeëŠ” ê²€ì¶œ íš¨ìœ¨(DQE)ë§Œ ì˜í–¥, Î”Î¼ íšŒë³µ ë¶ˆê°€
- "ì„ ëŸ‰ ì¦ê°€ë¡œ ëŒ€ì¡°ë„/MTF íšŒë³µ ê°€ëŠ¥" âŒ â†’ ì •ë‹µ: ì„ ëŸ‰ì€ ë…¸ì´ì¦ˆë§Œ ê°ì†Œ, Î”Î¼ì™€ MTFëŠ” ë¬´ê´€

## í˜•íƒœ ë³€í™” ì§ˆë¬¸ ì‹œ (Fine Linear, Amorphous ë“±)

ë°˜ë“œì‹œ **MTF ì†ì‹¤ê³¼ í˜•íƒœ ë³€í™”ì˜ ì—°ê²°**ì„ ì„¤ëª…:
- Fine LinearëŠ” 5-10 lp/mm í•´ìƒë„ í•„ìš”
- MTF_system < 0.2 at 5 lp/mm â†’ ê³ ì£¼íŒŒ ì†ì‹¤ â†’ ì„ ì´ ì ìœ¼ë¡œ ë³´ì„
- ë¹” ê²½í™” â†’ CsI ê¹Šì´ ì¹¨íˆ¬ â†’ ë¹› í™•ì‚° â†’ MTF ì €í•˜

## ì¶œë ¥ í˜•ì‹

ìì—°ìŠ¤ëŸ¬ìš´ í•œêµ­ì–´ ë¬¸ì¥ìœ¼ë¡œ ë‹µë³€í•˜ì„¸ìš”. ë‹¤ìŒ êµ¬ì¡° ê¶Œì¥:

1. **ì›ì¸ ë¶„ì„**: ë¬¼ë¦¬ì  ë©”ì»¤ë‹ˆì¦˜ ì„¤ëª…
2. **ê³„ì‚°/ìˆ˜ì¹˜**: ê´€ë ¨ ê³µì‹ê³¼ ê³„ì‚° (ìˆìœ¼ë©´)
3. **ê²°ë¡ **: ì„ìƒì  ì˜ë¯¸

ìˆ˜ì‹ì€ $ê¸°í˜¸$ ë˜ëŠ” $$ë¸”ë¡$$ìœ¼ë¡œ í‘œê¸°."""

        user_prompt = self._build_draft_prompt(
            question=question,
            context=context,
            physics_knowledge=physics_knowledge
        )

        try:
            response = self._call_llm(
                system_prompt=system_prompt,
                user_prompt=user_prompt,
                model=self.config.reasoning_model,
                timeout=self.config.draft_timeout
            )

            # Phase 7.14: JSON íŒŒì‹± ì œê±° - ìì—°ì–´ í…ìŠ¤íŠ¸ ì§ì ‘ ì‚¬ìš©
            if response.strip():
                # ì½”ë“œ ë¸”ë¡ ë§ˆì»¤, think íƒœê·¸ ì œê±°
                clean_response = re.sub(r'```\w*\s*|\s*```', '', response)
                clean_response = re.sub(r'<think>.*?</think>', '', clean_response, flags=re.DOTALL)
                clean_response = clean_response.strip()

                # í›„ì²˜ë¦¬ ì ìš©
                content = self._postprocess_answer(clean_response)

                # ì‹ ë¢°ë„ ì¶”ì •: í•µì‹¬ í‚¤ì›Œë“œ í¬í•¨ ì—¬ë¶€ë¡œ íŒë‹¨
                confidence = 0.7
                if any(kw in content.lower() for kw in ['mtf', 'í•´ìƒë„', 'lp/mm']):
                    confidence += 0.1
                if any(kw in content for kw in ['Î”Î¼', 'delta', 'ëŒ€ì¡°ë„']):
                    confidence += 0.1
                if 'ì„ ëŸ‰' in content and ('ë¬´ê´€' in content or 'ë…¸ì´ì¦ˆ' in content):
                    confidence += 0.1

                logger.info(f"Stage 1 ì™„ë£Œ: {len(content)} chars, confidence={confidence:.2f}")

                return DraftAnswer(
                    content=content,
                    derivation="",
                    evidence_citations=[],
                    formula_checks=[],
                    confidence=min(confidence, 0.95)
                )
            else:
                # Phase 7.15: ë¹ˆ ì‘ë‹µ ì‹œ fallback
                logger.warning("Stage 1: LLM ì‘ë‹µì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤")
                return DraftAnswer(
                    content="LLM ì‘ë‹µì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì„¸ìš”.",
                    derivation="",
                    evidence_citations=[],
                    formula_checks=[],
                    confidence=0.1
                )

        except Exception as e:
            logger.error(f"Stage 1 draft error: {e}")
            return DraftAnswer(
                content=f"ì¶”ë¡  ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}",
                derivation="",
                evidence_citations=[],
                formula_checks=[],
                confidence=0.0
            )

    def _smart_truncate_knowledge(self, knowledge: str, max_chars: int = 4000) -> str:
        """
        Phase 7.12: ìŠ¤ë§ˆíŠ¸ ì§€ì‹ truncation

        ìš°ì„ ìˆœìœ„:
        1. âš ï¸ ê²½ê³  ì„¹ì…˜ (ë¬¼ë¦¬ ì˜¤ë¥˜ ë°©ì§€ - MUST AVOID)
        2. í•µì‹¬ ë¬¼ë¦¬ ë‚´ìš© ì•ë¶€ë¶„
        3. ë‚˜ë¨¸ì§€ ë‚´ìš©

        Args:
            knowledge: ì›ë³¸ ì§€ì‹ í…ìŠ¤íŠ¸ (ë§ˆí¬ë‹¤ìš´ í¬ë§·)
            max_chars: ìµœëŒ€ ë¬¸ì ìˆ˜

        Returns:
            ìš°ì„ ìˆœìœ„ì— ë”°ë¼ truncationëœ ì§€ì‹ í…ìŠ¤íŠ¸
        """
        if not knowledge or len(knowledge) <= max_chars:
            return knowledge

        # ìš°ì„ ìˆœìœ„ ì„¹ì…˜ ì¶”ì¶œ (ë§ˆí¬ë‹¤ìš´ í¬ë§· ì§€ì›)
        priority_sections = []

        # ë§ˆí¬ë‹¤ìš´ í¬ë§·: âš ï¸ ê²½ê³  ë¸”ë¡ ì¶”ì¶œ
        # "============" êµ¬ë¶„ì„  ì‚¬ì´ì˜ ê²½ê³  ì„¹ì…˜
        warning_pattern = r'={10,}\s*âš ï¸ ê²½ê³ .*?={10,}(?:\s*ğŸ“¢.*?(?=##|\Z))?'
        warning_matches = re.findall(warning_pattern, knowledge, re.DOTALL)
        for match in warning_matches:
            if match and len(match) > 100:
                priority_sections.append(match.strip())

        # JSON í¬ë§·: common_misconceptions, critical_concept_separation
        json_patterns = [
            r'"common_misconceptions"\s*:\s*\{[^{}]*(?:\{[^{}]*\}[^{}]*)*\}',
            r'"critical_concept_separation"\s*:\s*\{[^{}]*(?:\{[^{}]*\}[^{}]*)*\}',
            r'"mtf_morphology_connection"\s*:\s*\{[^{}]*(?:\{[^{}]*\}[^{}]*)*\}',
        ]
        for pattern in json_patterns:
            matches = re.findall(pattern, knowledge, re.DOTALL)
            for match in matches:
                if match and len(match) > 50:
                    priority_sections.append(match)

        # ì¤‘ë³µ ì œê±° ë° ì›ë³¸ì—ì„œ ì œê±°
        remaining_knowledge = knowledge
        total_priority_chars = 0
        for section in priority_sections:
            total_priority_chars += len(section)
            remaining_knowledge = remaining_knowledge.replace(section, "")

        # ìš°ì„ ìˆœìœ„ ì„¹ì…˜ì´ max_charsì˜ 70% ì´ˆê³¼í•˜ë©´ ì¶•ì†Œ
        max_priority = int(max_chars * 0.7)
        if total_priority_chars > max_priority:
            ratio = max_priority / total_priority_chars
            priority_sections = [s[:int(len(s) * ratio)] for s in priority_sections]
            total_priority_chars = sum(len(s) for s in priority_sections)

        # ë‚¨ì€ ê³µê°„ì— ë‚˜ë¨¸ì§€ ë‚´ìš© ì¶”ê°€
        remaining_space = max_chars - total_priority_chars - 100

        if remaining_space > 300:
            # í•µì‹¬ ë¬¼ë¦¬ ë‚´ìš© ì„¹ì…˜ ìš°ì„ 
            physics_start = remaining_knowledge.find("## í•µì‹¬ ë¬¼ë¦¬ ë‚´ìš©")
            if physics_start >= 0:
                remaining_truncated = remaining_knowledge[physics_start:physics_start + remaining_space]
            else:
                remaining_truncated = remaining_knowledge[:remaining_space]
            # ë§ˆì§€ë§‰ ì™„ì „í•œ ì¤„ì—ì„œ ìë¥´ê¸°
            last_newline = remaining_truncated.rfind('\n')
            if last_newline > remaining_space * 0.6:
                remaining_truncated = remaining_truncated[:last_newline]
        else:
            remaining_truncated = ""

        # ê²°í•©: ê²½ê³  ì„¹ì…˜ì„ ë¨¼ì € ë°°ì¹˜
        if priority_sections:
            # ê²½ê³  ì„¹ì…˜ì´ ìˆìœ¼ë©´ ê·¸ëŒ€ë¡œ ì‚¬ìš© (ì´ë¯¸ í¬ë§·ë¨)
            result = "\n\n".join(priority_sections)
            if remaining_truncated:
                result += "\n\n" + remaining_truncated
        else:
            # ê²½ê³  ì„¹ì…˜ì´ ì—†ìœ¼ë©´ ì•ë¶€ë¶„ truncation
            result = knowledge[:max_chars]
            last_newline = result.rfind('\n')
            if last_newline > max_chars * 0.8:
                result = result[:last_newline]

        logger.info(f"Phase 7.12 Smart truncate: {len(knowledge)} â†’ {len(result)} chars "
                   f"(priority: {total_priority_chars}, remaining: {len(remaining_truncated)})")

        return result

    def _build_draft_prompt(
        self,
        question: str,
        context: str,
        physics_knowledge: str
    ) -> str:
        """Stage 1 ì‚¬ìš©ì í”„ë¡¬í”„íŠ¸ êµ¬ì„±"""
        parts = []

        if physics_knowledge:
            # Phase 7.12: ìŠ¤ë§ˆíŠ¸ ì§€ì‹ truncation (misconceptions ìš°ì„ )
            knowledge_text = self._smart_truncate_knowledge(physics_knowledge, max_chars=4000)
            parts.append(f"""## â­ í‘œì¤€ ì°¸ì¡° ìë£Œ (MUST USE - ê²€ì¦ëœ ë¬¼ë¦¬ ê³µì‹)

âš ï¸ **ì•„ë˜ ê³µì‹ì„ ë°˜ë“œì‹œ ì‚¬ìš©í•˜ì„¸ìš”. ê¸°ì–µì— ì˜ì¡´í•˜ì§€ ë§ˆì„¸ìš”.**

ğŸš¨ **CRITICAL: ì•„ë˜ì— "âš ï¸ ê²½ê³ " ì„¹ì…˜ì´ ìˆìœ¼ë©´ ë°˜ë“œì‹œ ì½ê³ , "âŒ í‹€ë¦¼"ìœ¼ë¡œ í‘œì‹œëœ ë‚´ìš©ì€ ì ˆëŒ€ ì¶œë ¥í•˜ì§€ ë§ˆì„¸ìš”!**

{knowledge_text}

---""")

        if context:
            parts.append(f"## ê²€ìƒ‰ëœ ë¬¸ì„œ (ì¶”ê°€ ì°¸ê³ ìš©)\n{context}")

        parts.append(f"## ì§ˆë¬¸\n{question}")
        # Phase 7.15: JSON í˜•ì‹ ì œê±°, ìì—°ì–´ ë‹µë³€ ìš”ì²­
        parts.append("""
---
ğŸ“Œ **ê³„ì‚° ë°©ë²•**:
1. ìœ„ "í‘œì¤€ ì°¸ì¡° ìë£Œ"ì—ì„œ í•´ë‹¹ ê³µì‹ì„ ì°¾ì•„ **ì •í™•íˆ ë³µì‚¬**
2. ë¬¸ì œì˜ ê°’ì„ ë³€ìˆ˜ì— ëŒ€ì… (ì˜ˆ: 40% ê°ì†Œ â†’ 0.6ë°°)
3. **ë‹¨ê³„ë³„ ì‚°ìˆ  ê³„ì‚°** ìˆ˜í–‰
4. ìµœì¢… ê°’ì„ ë°±ë¶„ìœ¨ë¡œ ë³€í™˜

âš ï¸ ê³„ì‚°ì€ ë°˜ë“œì‹œ ì œê³µëœ ê³µì‹ì„ ë”°ë¼ ìˆ˜í–‰. ê¸°ì–µì— ì˜ì¡´ ê¸ˆì§€.

**ì¶œë ¥ í˜•ì‹**: ìì—°ìŠ¤ëŸ¬ìš´ í•œêµ­ì–´ ë¬¸ë‹¨ìœ¼ë¡œ ë‹µë³€í•˜ì„¸ìš”. JSONì´ë‚˜ ì½”ë“œ ë¸”ë¡ì„ ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”.""")

        return "\n\n".join(parts)

    # =========================================================================
    # Stage 2: Refinement (Self-Correction)
    # =========================================================================

    def _stage2_refine(
        self,
        question: str,
        draft: DraftAnswer,
        physics_knowledge: str
    ) -> RefinedAnswer:
        """
        2ë‹¨ê³„: Self-Correction ë° ì •ì œ

        - ë…¼ë¦¬ì  í—ˆì  íƒì§€
        - BI-RADS ê°€ì´ë“œë¼ì¸ ìœ„ë°˜ ê²€ì¦
        - ìˆ˜ì¹˜ ì˜¤ë¥˜ ê²€ì¶œ
        """
        # Phase 7.14: ë‹¨ìˆœí™”ëœ ê²€ì¦ í”„ë¡¬í”„íŠ¸
        system_prompt = """ë‹¹ì‹ ì€ ë¬¼ë¦¬í•™ ë‹µë³€ ê²€ì¦ìì…ë‹ˆë‹¤. ì´ˆì•ˆì„ ê²€í† í•˜ê³  ì˜¤ë¥˜ê°€ ìˆìœ¼ë©´ ìˆ˜ì •í•˜ì„¸ìš”.

## ê²€ì¦ í•­ëª©

1. **ë¬¼ë¦¬ ì˜¤ë¥˜ í™•ì¸** - ë‹¤ìŒ ì˜¤ë¥˜ê°€ ìˆìœ¼ë©´ ìˆ˜ì •:
   - "ë¹” ê²½í™”ê°€ ëŒ€ì¡°ë„ë¥¼ í–¥ìƒ" âŒ â†’ ë¹” ê²½í™”ëŠ” ëŒ€ì¡°ë„ **ê°ì†Œ** (Î¼_pe âˆ 1/EÂ³)
   - "K-edgeê°€ ëŒ€ì¡°ë„ ì†ì‹¤ ë³´ìƒ" âŒ â†’ K-edgeëŠ” DQEë§Œ ì˜í–¥, Î”Î¼ íšŒë³µ ë¶ˆê°€
   - "ì„ ëŸ‰ìœ¼ë¡œ MTF/ëŒ€ì¡°ë„ íšŒë³µ" âŒ â†’ ì„ ëŸ‰ì€ ë…¸ì´ì¦ˆë§Œ ê°ì†Œ

2. **MTF-í˜•íƒœ ì—°ê²° í™•ì¸** (Fine Linear/Amorphous ì–¸ê¸‰ ì‹œ):
   - MTF ì†ì‹¤ â†’ ê³ ì£¼íŒŒ ì†ì‹¤ â†’ ì„ ì´ ì ìœ¼ë¡œ ë³´ì„ ì„¤ëª… ìˆëŠ”ê°€?

3. **ê³„ì‚° ê²€ì¦** - ìˆ˜ì¹˜ê°€ ìˆìœ¼ë©´ ê³„ì‚°ì´ ë§ëŠ”ì§€ í™•ì¸

## ì¶œë ¥

ì˜¤ë¥˜ê°€ ìˆìœ¼ë©´ ìˆ˜ì •ëœ ë‹µë³€ì„, ì—†ìœ¼ë©´ "ê²€ì¦ ì™„ë£Œ: [ì›ë³¸ ìœ ì§€]"ë¥¼ ì¶œë ¥í•˜ì„¸ìš”.
í•œêµ­ì–´ë¡œ ìì—°ìŠ¤ëŸ½ê²Œ ì‘ì„±."""

        # Phase 7.14: ë‹¨ìˆœí™”ëœ user_prompt
        user_prompt = f"""## ì§ˆë¬¸
{question}

## ì´ˆì•ˆ ë‹µë³€
{draft.content}

ìœ„ ì´ˆì•ˆì— ë¬¼ë¦¬ ì˜¤ë¥˜ê°€ ìˆìœ¼ë©´ ìˆ˜ì •í•˜ê³ , ì—†ìœ¼ë©´ ê·¸ëŒ€ë¡œ ì¶œë ¥í•˜ì„¸ìš”."""

        try:
            response = self._call_llm(
                system_prompt=system_prompt,
                user_prompt=user_prompt,
                model=self.config.critic_model,
                timeout=self.config.refine_timeout
            )

            # Phase 7.14: JSON íŒŒì‹± ì œê±° - ìì—°ì–´ í…ìŠ¤íŠ¸ ì§ì ‘ ì‚¬ìš©
            if response.strip():
                clean_response = re.sub(r'```\w*\s*|\s*```', '', response)
                clean_response = re.sub(r'<think>.*?</think>', '', clean_response, flags=re.DOTALL)
                clean_response = clean_response.strip()

                # "ê²€ì¦ ì™„ë£Œ" ë˜ëŠ” "ì›ë³¸ ìœ ì§€" í¬í•¨ ì‹œ ì´ˆì•ˆ ì‚¬ìš©
                if 'ê²€ì¦ ì™„ë£Œ' in clean_response or 'ì›ë³¸ ìœ ì§€' in clean_response or len(clean_response) < 100:
                    content = draft.content
                    corrections = []
                    quality = AnswerQuality.GOOD
                else:
                    content = self._postprocess_answer(clean_response)
                    corrections = ["Stage 2ì—ì„œ ìˆ˜ì •ë¨"]
                    quality = AnswerQuality.EXCELLENT

                logger.info(f"Stage 2 ì™„ë£Œ: {len(content)} chars")

                return RefinedAnswer(
                    content=content,
                    derivation="",
                    evidence_mapping=[],
                    recommendation="",
                    quality=quality,
                    corrections_made=corrections,
                    final_confidence=draft.confidence + 0.1 if corrections else draft.confidence,
                    clinical_insight=""
                )

        except Exception as e:
            logger.error(f"Stage 2 refine error: {e}")
            # ì˜¤ë¥˜ ì‹œ ì´ˆì•ˆ ê·¸ëŒ€ë¡œ ë°˜í™˜
            return RefinedAnswer(
                content=draft.content,
                derivation=draft.derivation,
                evidence_mapping=[],
                recommendation="",
                quality=AnswerQuality.NEEDS_REVISION,
                corrections_made=[f"ê²€ì¦ ì‹¤íŒ¨: {str(e)}"],
                final_confidence=draft.confidence * 0.8,  # ì‹ ë¢°ë„ í•˜í–¥
                clinical_insight=""
            )

    # =========================================================================
    # Utilities
    # =========================================================================

    def _call_llm(
        self,
        system_prompt: str,
        user_prompt: str,
        model: str,
        timeout: int,
        max_retries: int = 3
    ) -> str:
        """
        LLM í˜¸ì¶œ (Phase 7.15: ì¬ì‹œë„ ë¡œì§ ì¶”ê°€)

        Args:
            max_retries: ë¹ˆ ì‘ë‹µ ì‹œ ìµœëŒ€ ì¬ì‹œë„ íšŸìˆ˜
        """
        import time

        for attempt in range(max_retries):
            try:
                response = requests.post(
                    f"{self.config.ollama_url}/api/chat",
                    json={
                        "model": model,
                        "messages": [
                            {"role": "system", "content": system_prompt},
                            {"role": "user", "content": user_prompt}
                        ],
                        "stream": False,
                        "options": {
                            "num_predict": 5000,
                            "temperature": 0.2 + (attempt * 0.1),  # ì¬ì‹œë„ ì‹œ ì˜¨ë„ ì•½ê°„ ì¦ê°€
                        }
                    },
                    timeout=timeout
                )

                response.raise_for_status()
                resp_data = response.json()
                content = resp_data.get("message", {}).get("content", "")

                # Phase 7.15: ë¹ˆ ì‘ë‹µ ì¬ì‹œë„
                if not content.strip():
                    # thinking í•„ë“œ í™•ì¸ (ì•„ë˜ ë¡œì§ì—ì„œ ì²˜ë¦¬)
                    thinking = resp_data.get("message", {}).get("thinking", "")
                    if not thinking:
                        if attempt < max_retries - 1:
                            logger.warning(f"LLM ë¹ˆ ì‘ë‹µ (ì‹œë„ {attempt + 1}/{max_retries}), ì¬ì‹œë„ ì¤‘...")
                            time.sleep(1)  # 1ì´ˆ ëŒ€ê¸° í›„ ì¬ì‹œë„
                            continue
                        else:
                            logger.error(f"LLM ë¹ˆ ì‘ë‹µ (ëª¨ë“  ì¬ì‹œë„ ì‹¤íŒ¨)")
                            return ""

                break  # ì„±ê³µ ì‹œ ë£¨í”„ íƒˆì¶œ

            except requests.exceptions.Timeout:
                if attempt < max_retries - 1:
                    logger.warning(f"LLM íƒ€ì„ì•„ì›ƒ (ì‹œë„ {attempt + 1}/{max_retries}), ì¬ì‹œë„ ì¤‘...")
                    time.sleep(2)
                    continue
                else:
                    raise
            except Exception as e:
                if attempt < max_retries - 1:
                    logger.warning(f"LLM ì˜¤ë¥˜ (ì‹œë„ {attempt + 1}/{max_retries}): {e}, ì¬ì‹œë„ ì¤‘...")
                    time.sleep(1)
                    continue
                else:
                    raise

        # Phase 7.7: thinking ëª¨ë“œ ëŒ€ì‘ (gpt-oss:20b, deepseek-r1 ë“±)
        # contentê°€ ë¹„ì–´ìˆìœ¼ë©´ thinking í•„ë“œì—ì„œ JSON ì¶”ì¶œ ì‹œë„
        if not content.strip():
            thinking = resp_data.get("message", {}).get("thinking", "")
            if thinking:
                # thinking í•„ë“œì—ì„œ JSON ë¸”ë¡ ì¶”ì¶œ
                json_match = re.search(r'```json\s*(.*?)\s*```', thinking, re.DOTALL)
                if json_match:
                    content = json_match.group(1)  # JSON ë‚´ìš©ë§Œ (ì½”ë“œ ë¸”ë¡ ë§ˆì»¤ ì œì™¸)
                else:
                    # ì¤‘ê´„í˜¸ë¡œ ì‹œì‘í•˜ëŠ” JSON ì°¾ê¸° (ì¤‘ì²© í—ˆìš©)
                    brace_match = re.search(r'\{[^}]*"(?:answer|derivation)".*\}', thinking, re.DOTALL)
                    if brace_match:
                        content = brace_match.group()
                logger.debug(f"Extracted from thinking field: {content[:200] if content else 'EMPTY'}")

        # DeepSeek-R1 <think> íƒœê·¸ ì œê±°
        content = re.sub(r'<think>.*?</think>', '', content, flags=re.DOTALL)

        # Phase 7.11: Misconception í•„í„° ì ìš©
        content = self._filter_physics_misconceptions(content)

        return content.strip()

    def _filter_physics_misconceptions(self, content: str) -> str:
        """
        Phase 7.11: LLM ì¶œë ¥ì—ì„œ ì•Œë ¤ì§„ ë¬¼ë¦¬ ì˜¤ë¥˜ë¥¼ ê°ì§€í•˜ê³  ìˆ˜ì •

        LLMì´ ì§€ì‹œë¥¼ ë¬´ì‹œí•˜ê³  ì˜ëª»ëœ ë¬¼ë¦¬ë¥¼ ìƒì„±í•  ê²½ìš°, ì´ë¥¼ ê°ì§€í•˜ê³  ê²½ê³ ë¥¼ ì¶”ê°€í•©ë‹ˆë‹¤.
        """
        if not content:
            return content

        misconceptions_detected = []
        corrections = []

        # 1. K-edge ê°’ ì˜¤ë¥˜ ê°ì§€ (CsI = 33keV, Iodine = 33.2keV)
        # ì˜ëª»ëœ K-edge ê°’: 29keV, 30keV ë“±
        kedge_wrong_patterns = [
            (r'K.?edge.*?(\d{2})\s*keV', lambda m: int(m.group(1)) not in [33, 34]),  # 33-34 keV ë²”ìœ„ í—ˆìš©
            (r'(\d{2})\s*keV.*?K.?edge', lambda m: int(m.group(1)) not in [33, 34]),
        ]
        for pattern, is_wrong in kedge_wrong_patterns:
            for match in re.finditer(pattern, content, re.IGNORECASE):
                if is_wrong(match):
                    wrong_value = match.group(1)
                    misconceptions_detected.append(f"K-edge {wrong_value}keV (ì •í™•í•œ ê°’: CsI/Iodine K-edge = 33keV)")
                    # ìˆ˜ì •í•˜ì§€ ì•Šê³  ê²½ê³ ë§Œ ì¶”ê°€ (ì›ë¬¸ ë³´ì¡´)

        # 2. ë¹” ê²½í™”ê°€ ëŒ€ì¡°ë„ë¥¼ í–¥ìƒì‹œí‚¨ë‹¤ëŠ” ì˜¤ë¥˜
        beam_hardening_wrong = [
            r'ë¹”\s*ê²½í™”.*?(?:í–¥ìƒ|ê°œì„ |ì¦ê°€).*?(?:ëŒ€ì¡°ë„|DQE|CNR)',
            r'beam\s*hardening.*?(?:improve|increase|enhance).*?(?:contrast|DQE|CNR)',
            r'ê²½í™”ëœ.*?ë¹”.*?(?:ëŒ€ì¡°ë„|DQE|CNR).*?(?:í–¥ìƒ|ê°œì„ |ì¦ê°€)',
        ]
        for pattern in beam_hardening_wrong:
            if re.search(pattern, content, re.IGNORECASE):
                misconceptions_detected.append(
                    "ë¹” ê²½í™”ê°€ ëŒ€ì¡°ë„ë¥¼ í–¥ìƒì‹œí‚¨ë‹¤ëŠ” ì˜¤ë¥˜ ê°ì§€ "
                    "(ì •í™•: ë¹” ê²½í™”ëŠ” Î¼_pe âˆ 1/EÂ³ë¡œ ì¸í•´ ëŒ€ì¡°ë„ë¥¼ ê°ì†Œì‹œí‚´)"
                )

        # 3. K-edgeê°€ ëŒ€ì¡°ë„ ì†ì‹¤ì„ ë³´ìƒí•œë‹¤ëŠ” ì˜¤ë¥˜
        kedge_compensation_wrong = [
            r'K.?edge.*?(?:ë³´ìƒ|íšŒë³µ|ë³µì›).*?(?:ëŒ€ì¡°ë„|contrast|Î”Î¼)',
            r'(?:ëŒ€ì¡°ë„|contrast|Î”Î¼).*?(?:ë³´ìƒ|íšŒë³µ|ë³µì›).*?K.?edge',
        ]
        for pattern in kedge_compensation_wrong:
            if re.search(pattern, content, re.IGNORECASE):
                misconceptions_detected.append(
                    "K-edgeê°€ ëŒ€ì¡°ë„ ì†ì‹¤ì„ ë³´ìƒí•œë‹¤ëŠ” ì˜¤ë¥˜ ê°ì§€ "
                    "(ì •í™•: K-edgeëŠ” ê²€ì¶œ íš¨ìœ¨(DQE)ì—ë§Œ ì˜í–¥, í”¼ì‚¬ì²´ ëŒ€ì¡°ë„(Î”Î¼)ëŠ” íšŒë³µ ë¶ˆê°€)"
                )

        # 4. ì‚°ë€ì„  ê³µì‹ ì˜¤ë¥˜: Cs = Câ‚€ Ã— (1 - SPR)
        scatter_formula_wrong = [
            r'C[sâ‚€]?\s*=\s*C[â‚€0]?\s*[Ã—x\*]\s*\(?\s*1\s*-\s*SPR',
            r'C[sâ‚€]?\s*=\s*C[â‚€0]?\s*\(1\s*-\s*SPR\)',
        ]
        for pattern in scatter_formula_wrong:
            if re.search(pattern, content, re.IGNORECASE):
                misconceptions_detected.append(
                    "ì‚°ë€ì„  ê³µì‹ ì˜¤ë¥˜: Cs = Câ‚€ Ã— (1 - SPR) "
                    "(ì •í™•í•œ ê³µì‹: Cs = Câ‚€ / (1 + SPR))"
                )

        # 5. Fine Linear â†’ Amorphous ë³€í™”ê°€ MTFì™€ ë¬´ê´€í•˜ë‹¤ëŠ” ì˜¤ë¥˜
        # (ì´ ë³€í™”ê°€ ì–¸ê¸‰ë˜ì—ˆëŠ”ë° MTF/ê³ ì£¼íŒŒ ì†ì‹¤ ì–¸ê¸‰ì´ ì—†ìœ¼ë©´ ê²½ê³ )
        if re.search(r'Fine\s*Linear.*?Amorphous|4C.*?4B', content, re.IGNORECASE):
            if not re.search(r'MTF|ê³ ì£¼íŒŒ|high.?frequency|í•´ìƒë„|resolution', content, re.IGNORECASE):
                misconceptions_detected.append(
                    "Fine Linear â†’ Amorphous í˜•íƒœ ë³€í™”ì— MTF/ê³ ì£¼íŒŒ ì†ì‹¤ ì„¤ëª… ëˆ„ë½ "
                    "(ì •í™•: ê³ ì£¼íŒŒ(2-5 lp/mm) MTF ì†ì‹¤ë¡œ ì¸í•´ ì„ í˜• êµ¬ì¡°ê°€ ì í˜•ìœ¼ë¡œ ë³´ì„)"
                )

        # ê²½ê³  ì¶”ê°€ (ì‹¬ê°í•œ ì˜¤ë¥˜ê°€ ìˆìœ¼ë©´ ì¶œë ¥ ì•ì— ê²½ê³  ë°°ë„ˆ ì¶”ê°€)
        if misconceptions_detected:
            warning_banner = (
                "\n\nâš ï¸ **ë¬¼ë¦¬ ê²€ì¦ ê²½ê³ ** (Phase 7.11 Misconception Filter):\n"
                "LLM ì¶œë ¥ì—ì„œ ë‹¤ìŒ ë¬¼ë¦¬ ì˜¤ë¥˜ê°€ ê°ì§€ë˜ì—ˆìŠµë‹ˆë‹¤:\n"
            )
            for i, misconception in enumerate(misconceptions_detected, 1):
                warning_banner += f"{i}. {misconception}\n"
            warning_banner += "\n---\n\n"

            logger.warning(f"Physics misconceptions detected: {misconceptions_detected}")

            # ì¶œë ¥ ì•ì— ê²½ê³  ì¶”ê°€ (ì›ë¬¸ì€ ë³´ì¡´)
            content = warning_banner + content

        return content

    def _parse_json_response(self, response: str) -> Dict:
        """JSON ì‘ë‹µ íŒŒì‹± (ì½”ë“œ ë¸”ë¡ ì²˜ë¦¬ + í‚¤ ì •ê·œí™”)"""
        if not response or not response.strip():
            return {}

        # ```json ... ``` ë¸”ë¡ ì¶”ì¶œ
        json_match = re.search(r'```json\s*(.*?)\s*```', response, re.DOTALL)
        if json_match:
            json_str = json_match.group(1)
        else:
            # ì½”ë“œ ë¸”ë¡ ì—†ì´ ì§ì ‘ JSONì¸ ê²½ìš°
            json_str = response

        parsed = {}
        try:
            parsed = json.loads(json_str)
        except json.JSONDecodeError:
            # ì‹œë„ 2: ì¤‘ê´„í˜¸ë¡œ ê°ì‹¸ì§„ ë¶€ë¶„ ì¶”ì¶œ
            brace_match = re.search(r'\{.*\}', response, re.DOTALL)
            if brace_match:
                try:
                    parsed = json.loads(brace_match.group())
                except json.JSONDecodeError:
                    # Phase 7.7: ì˜ë¦° JSON ë³µêµ¬ ì‹œë„ (í† í° ì œí•œìœ¼ë¡œ JSONì´ ì¤‘ê°„ì— ëŠê¸´ ê²½ìš°)
                    truncated = brace_match.group()
                    # ì—´ë¦° ì¤‘ê´„í˜¸/ëŒ€ê´„í˜¸ ìˆ˜ ê³„ì‚°í•˜ì—¬ ë‹«ê¸°
                    open_braces = truncated.count('{') - truncated.count('}')
                    open_brackets = truncated.count('[') - truncated.count(']')
                    # ë§ˆì§€ë§‰ ì™„ì „í•œ key-value ìŒ ì´í›„ ìë¥´ê¸°
                    last_comma = truncated.rfind('",')
                    if last_comma > 0:
                        truncated = truncated[:last_comma + 1]
                    truncated += ']' * open_brackets + '}' * open_braces
                    try:
                        parsed = json.loads(truncated)
                        logger.info(f"Recovered truncated JSON (added {open_braces} braces)")
                    except:
                        pass

        # Phase 7.5: í•œêµ­ì–´/ëŒ€ì²´ í‚¤ë¥¼ ì˜ì–´ í‚¤ë¡œ ë§¤í•‘
        key_mapping = {
            # answer alternatives
            'ë‹µë³€': 'answer',
            'ìµœì¢…_ë‹µë³€': 'answer',
            'ìµœì¢…ë‹µë³€': 'answer',
            'final_answer': 'answer',
            'response': 'answer',
            # derivation alternatives
            'ì¦ëª…': 'derivation',
            'ì¦ëª…_ê³¼ì •': 'derivation',
            'ì¦ëª…ê³¼ì •': 'derivation',
            'ìœ ë„': 'derivation',
            'ë„ì¶œ_ê³¼ì •': 'derivation',
            'proof': 'derivation',
            'reasoning': 'derivation',
            # clinical_insight alternatives
            'ì„ìƒì _ì˜í–¥': 'clinical_insight',
            'ì„ìƒì˜í–¥': 'clinical_insight',
            'ì„ìƒ_í†µì°°': 'clinical_insight',
            'clinical_impact': 'clinical_insight',
            # confidence alternatives
            'ì‹ ë¢°ë„': 'confidence',
            'í™•ì‹ ë„': 'confidence',
        }

        normalized = {}
        for key, value in parsed.items():
            # ê³µë°±ê³¼ ì–¸ë”ìŠ¤ì½”ì–´ ì •ê·œí™”
            normalized_key = key.strip().replace(' ', '_')
            # ë§¤í•‘ ì ìš©
            if normalized_key in key_mapping:
                normalized[key_mapping[normalized_key]] = value
            else:
                normalized[key] = value

        return normalized if normalized else parsed

    # =========================================================================
    # Phase 7.5: Post-processing (LaTeX & Language)
    # =========================================================================

    def _apply_latex_formatting(self, text: str) -> str:
        """
        í”Œë ˆì¸í…ìŠ¤íŠ¸ ìˆ˜ì‹ì„ LaTeXë¡œ ë³€í™˜ (Phase 7.5)

        ë³€í™˜ ê·œì¹™:
        - ë¬¼ë¦¬ëŸ‰ ì•½ì–´: DQE, CNR, SNR, MTF â†’ $\text{...}$
        - ìˆ˜ì‹ íŒ¨í„´: sqrt, ë¶„ìˆ˜, ì²¨ì ë“±
        - ê·¸ë¦¬ìŠ¤ ë¬¸ì: Ïƒ, Î±, Î² ë“±
        """
        if not text:
            return text

        result = text

        # 1. ì´ë¯¸ LaTeXë¡œ ê°ì‹¸ì§„ ë¶€ë¶„ì€ ê±´ë“œë¦¬ì§€ ì•ŠìŒ
        # ì„ì‹œë¡œ ë³´í˜¸ ë§ˆì»¤ ì‚¬ìš©
        protected = []
        def protect_latex(m):
            protected.append(m.group(0))
            return f"__LATEX_{len(protected)-1}__"

        result = re.sub(r'\$\$[^$]+\$\$', protect_latex, result)
        result = re.sub(r'\$[^$]+\$', protect_latex, result)

        # 2. ë¬¼ë¦¬ëŸ‰ ì•½ì–´ë¥¼ LaTeXë¡œ ë³€í™˜ (í•œê¸€ ì¡°ì‚¬ ì•ì—ì„œë„ ë™ì‘)
        # ë‹¨ì–´ ëì´ ì˜ë¬¸ìì´ê±°ë‚˜ ìˆ«ìì¸ ê²½ìš°ë§Œ ë§¤ì¹­ (í•œê¸€ ì¡°ì‚¬ ì• í—ˆìš©)
        physics_terms = ['DQE', 'CNR', 'SNR', 'MTF', 'NPS', 'NEQ', 'SDNR', 'ROC', 'ALARA']

        for term in physics_terms:
            # ë‹¨ì–´ ì•ì— ì˜ë¬¸ìê°€ ì—†ê³ , ë’¤ì— ì˜ë¬¸ì/ìˆ«ìê°€ ì•„ë‹Œ ê²½ìš° ë§¤ì¹­
            pattern = rf'(?<![A-Za-z]){term}(?![A-Za-z0-9_])'
            result = re.sub(pattern, rf'$\\text{{{term}}}$', result)

        # 3. ì¸¡ì • ë‹¨ìœ„ íŒ¨í„´ (ì˜ˆ: "5 lp/mm", "0.35-0.45")
        result = re.sub(
            r'(\d+(?:\.\d+)?)\s*lp/mm',
            r'$\1\\ \\text{lp/mm}$',
            result
        )

        # 4. DQE/MTF with frequency (ì˜ˆ: "DQE(5 lp/mm)")
        result = re.sub(
            r'\$\\text\{(DQE|MTF)\}\$\s*\((\d+(?:\.\d+)?)\s*(?:lp/mm)?\)',
            r'$\\text{\1}(\2\\ \\text{lp/mm})$',
            result
        )

        # 5. ê·¸ë¦¬ìŠ¤ ë¬¸ì ë³€í™˜
        greek_letters = {
            'Ïƒ': r'$\sigma$',
            'Î±': r'$\alpha$',
            'Î²': r'$\beta$',
            'Î³': r'$\gamma$',
            'Î”': r'$\Delta$',
            'âˆš': r'$\sqrt{}$',
            'âˆ': r'$\propto$',
            'â‰¥': r'$\geq$',
            'â‰¤': r'$\leq$',
            'Ã—': r'$\times$',
        }

        for char, latex in greek_letters.items():
            result = result.replace(char, latex)

        # 6. ì²¨ì íŒ¨í„´ (ì˜ˆ: "Ïƒ_rel", "Ïƒ_abs") - ì˜ë¬¸ ì²¨ìë§Œ ì²˜ë¦¬
        result = re.sub(
            r'(\$\\sigma\$)_([a-zA-Z]+)',
            r'$\\sigma_{\\text{\2}}$',
            result
        )
        # Ïƒ_rel íŒ¨í„´ (ì•„ì§ ë³€í™˜ ì•ˆëœ ê²½ìš°)
        result = re.sub(
            r'Ïƒ_([a-zA-Z]+)',
            r'$\\sigma_{\\text{\1}}$',
            result
        )

        # 7. ë¶„ìˆ˜/ë¹„ìœ¨ íŒ¨í„´ (ì˜ˆ: "DQE_new / DQE_old")
        result = re.sub(
            r'\$\\text\{(\w+)\}\$_(\w+)\s*/\s*\$\\text\{(\w+)\}\$_(\w+)',
            r'$\\frac{\\text{\1}_{\\text{\2}}}{\\text{\3}_{\\text{\4}}}$',
            result
        )

        # 8. ë°±ë¶„ìœ¨ ê°•ì¡° (ì˜ˆ: "29.1%") - ì´ë¯¸ boldê°€ ì•„ë‹Œ ê²½ìš°ë§Œ
        result = re.sub(
            r'(?<!\*\*)(\d+(?:\.\d+)?)\s*%(?!\*\*)',
            r'**\1%**',
            result
        )

        # 9. Rose Criterion ê°•ì¡° (ì´ë¯¸ boldê°€ ì•„ë‹Œ ê²½ìš°ë§Œ)
        result = re.sub(
            r'(?<!\*\*)(Rose\s*Criterion)(?!\*\*)',
            r'**\1**',
            result,
            flags=re.IGNORECASE
        )

        # 10. ë³´í˜¸ëœ LaTeX ë³µì›
        for i, original in enumerate(protected):
            result = result.replace(f"__LATEX_{i}__", original)

        # 11. ì´ì¤‘ bold ì •ë¦¬ (**** â†’ **)
        result = re.sub(r'\*{4,}', '**', result)

        return result

    def _remove_chinese_characters(self, text: str) -> str:
        """
        ì¤‘êµ­ì–´/ì¼ë³¸ì–´ ë¬¸ìë¥¼ í•œêµ­ì–´ë¡œ ì¹˜í™˜ (Phase 7.7)
        """
        if not text:
            return text

        # Phase 7.7: ì¼ë³¸ì–´ íˆë¼ê°€ë‚˜/ì¹´íƒ€ì¹´ë‚˜ í¬í•¨ ì—¬ë¶€ ê°ì§€
        # ì¼ë³¸ì–´ê°€ ë‹¤ìˆ˜ í¬í•¨ë˜ì–´ ìˆìœ¼ë©´ ê²½ê³  ë¡œê·¸
        hiragana_count = len(re.findall(r'[\u3040-\u309f]', text))
        katakana_count = len(re.findall(r'[\u30a0-\u30ff]', text))
        if hiragana_count + katakana_count > 10:
            logger.warning(f"Japanese characters detected ({hiragana_count} hiragana, {katakana_count} katakana) - model may have responded in Japanese")

        # ì¼ë³¸ì–´ â†’ í•œêµ­ì–´ ì¹˜í™˜ ë§µ (ë¬¼ë¦¬í•™ ìš©ì–´)
        japanese_to_korean = {
            'ã—ãŸãŒã£ã¦': 'ë”°ë¼ì„œ',
            'ã™ãªã‚ã¡': 'ì¦‰',
            'ãŸã ã—': 'ë‹¨,',
            'ã“ã“ã§': 'ì—¬ê¸°ì„œ',
            'ãŠã‚ˆã³': 'ë°',
            'ã¾ãŸã¯': 'ë˜ëŠ”',
            'ã«ãŠã‘ã‚‹': 'ì—ì„œì˜',
            'ã«ã¤ã„ã¦': 'ì— ëŒ€í•´',
            'ã«ã‚ˆã‚‹': 'ì— ì˜í•œ',
            'ã¨ã—ã¦': 'ë¡œì„œ',
            'ã§ã‚ã‚‹': 'ì´ë‹¤',
            'ã¨ãªã‚‹': 'ê°€ ëœë‹¤',
            'ã¨ã™ã‚‹': 'ë¡œ í•œë‹¤',
            'ãŒå¿…è¦': 'ì´ í•„ìš”',
            'ã‚’æº€ãŸã™': 'ë¥¼ ë§Œì¡±í•˜ëŠ”',
            'ã«å¯¾ã™ã‚‹': 'ì— ëŒ€í•œ',
            'ã®å ´åˆ': 'ì˜ ê²½ìš°',
            'çµè«–': 'ê²°ë¡ ',
            'å¤‰æ•°': 'ë³€ìˆ˜',
            'æ„å‘³': 'ì˜ë¯¸',
            'åˆæœŸ': 'ì´ˆê¸°',
            'é‡å­': 'ì–‘ì',
            'åˆ†æ•£': 'ë¶„ì‚°',
            'é›»å­': 'ì „ì',
            'ç·': 'ì´',
            'æ¯”ç‡': 'ë¹„ìœ¨',
            'è¨±å®¹': 'í—ˆìš©',
            'æ¤œå‡º': 'ê²€ì¶œ',
            'å‘ä¸Š': 'í–¥ìƒ',
            'æ¸›å°‘': 'ê°ì†Œ',
            'å¢—åŠ ': 'ì¦ê°€',
            'å¾®å°': 'ë¯¸ì„¸',
            'ãƒã‚¤ã‚º': 'ë…¸ì´ì¦ˆ',
            'ã‚³ãƒ³ãƒˆãƒ©ã‚¹ãƒˆ': 'ëŒ€ì¡°ë„',
            'ã‚¨ãƒãƒ«ã‚®ãƒ¼': 'ì—ë„ˆì§€',
            'ã‚¦ã‚§ã‚¤ãƒˆ': 'ê°€ì¤‘ì¹˜',
        }
        result = text
        for jp, kr in japanese_to_korean.items():
            result = result.replace(jp, kr)

        # ì¤‘êµ­ì–´ â†’ í•œêµ­ì–´ ì¹˜í™˜ ë§µ
        chinese_to_korean = {
            'å…¶ä¸­': 'ì—¬ê¸°ì„œ',
            'èƒ½åŠ›': 'ëŠ¥ë ¥',
            'æ›´é«˜çš„': 'ë” ë†’ì€',
            'æ›´ä½çš„': 'ë” ë‚®ì€',
            'æ›´é«˜': 'ë” ë†’ì€',
            'æ›´ä½': 'ë” ë‚®ì€',
            'çš„': '',  # ë‹¨ë… çš„ ì œê±°
            'æ˜¾è‘—': 'í˜„ì €íˆ',
            'é¡¯è‘—': 'í˜„ì €íˆ',
            'ç—…ç¶': 'ë³‘ë³€',
            'ç—…ç«ˆ': 'ë³‘ë³€',
            'æ£€å‡º': 'ê²€ì¶œ',
            'æª¢å‡º': 'ê²€ì¶œ',
            'æ²‰ç§¯': 'ì¹¨ì°©',
            'æ²‰ç©': 'ì¹¨ì°©',
            'é’™åŒ–': 'ì„íšŒí™”',
            'éˆ£åŒ–': 'ì„íšŒí™”',
            'å¾®å°': 'ë¯¸ì„¸í•œ',
            'å›¾åƒ': 'ì˜ìƒ',
            'åœ–åƒ': 'ì˜ìƒ',
            'è´¨é‡': 'í’ˆì§ˆ',
            'è³ªé‡': 'í’ˆì§ˆ',
            'å™ªå£°': 'ë…¸ì´ì¦ˆ',
            'å™ªè²': 'ë…¸ì´ì¦ˆ',
            'å‰‚é‡': 'ì„ ëŸ‰',
            'åŠ‘é‡': 'ì„ ëŸ‰',
            'æ¢æµ‹': 'ê²€ì¶œ',
            'æ¢æ¸¬': 'ê²€ì¶œ',
            'çµæ•åº¦': 'ë¯¼ê°ë„',
            'éˆæ•åº¦': 'ë¯¼ê°ë„',
            'ç‰¹å¼‚æ€§': 'íŠ¹ì´ë„',
            'ç‰¹ç•°æ€§': 'íŠ¹ì´ë„',
        }

        for chinese, korean in chinese_to_korean.items():
            result = result.replace(chinese, korean)

        # ë‚¨ì€ ì¤‘êµ­ì–´ ë¬¸ì ì œê±° (CJK Unified Ideographs ë²”ìœ„)
        # ì¼ë³¸ì–´ í•œìì™€ í•œêµ­ì–´ í•œìëŠ” ìœ ì§€í•˜ë˜, ë¬¸ë§¥ìƒ ì–´ìƒ‰í•œ ê²½ìš°ë§Œ ì²˜ë¦¬

        return result

    def _postprocess_answer(self, text: str) -> str:
        """
        ë‹µë³€ í›„ì²˜ë¦¬: LaTeX ìˆ˜ë¦¬ + ë³€í™˜ + ì¤‘êµ­ì–´ ì œê±° (Phase 7.5, 7.13)
        """
        if not text:
            return text

        # 0. Phase 7.13: ì†ìƒëœ LaTeX ë³µêµ¬ (\t â†’ \text ë“±)
        result = self._repair_corrupted_latex(text)

        # 1. ì¤‘êµ­ì–´ ì œê±°
        result = self._remove_chinese_characters(result)

        # 2. LaTeX ë³€í™˜
        result = self._apply_latex_formatting(result)

        return result

    def _repair_corrupted_latex(self, text: str) -> str:
        """
        Phase 7.13: ì†ìƒëœ LaTeX ëª…ë ¹ì–´ ë³µêµ¬

        ë¬¸ì œ: JSON ì§ë ¬í™”/ì—­ì§ë ¬í™” ê³¼ì •ì—ì„œ \\text â†’ \\t + ext (íƒ­ + ext)ë¡œ ë³€í™˜ë¨
        í•´ê²°: ì†ìƒëœ íŒ¨í„´ì„ ì›ë˜ LaTeX ëª…ë ¹ì–´ë¡œ ë³µêµ¬
        """
        if not text:
            return text

        result = text

        # 1. \tê°€ íƒ­ìœ¼ë¡œ ë³€í™˜ëœ ê²½ìš° ë³µêµ¬: íƒ­ + ext{ â†’ \text{
        result = result.replace('\text{', '\\text{')  # íƒ­+ext â†’ \text

        # 2. ì§ì ‘ ì†ìƒëœ íŒ¨í„´ ë³µêµ¬
        corrupted_patterns = [
            (r'\\ext\{', r'\\text{'),      # \ext{ â†’ \text{
            (r'\\frac\{', r'\\frac{'),      # ì´ë¯¸ ì˜¬ë°”ë¦„, í™•ì¸ìš©
            (r'\\sqrt\{', r'\\sqrt{'),      # ì´ë¯¸ ì˜¬ë°”ë¦„, í™•ì¸ìš©
            (r'\\sigma', r'\\sigma'),       # ì´ë¯¸ ì˜¬ë°”ë¦„, í™•ì¸ìš©
            (r'\\Delta', r'\\Delta'),       # ì´ë¯¸ ì˜¬ë°”ë¦„, í™•ì¸ìš©
            (r'\\propto', r'\\propto'),     # ì´ë¯¸ ì˜¬ë°”ë¦„, í™•ì¸ìš©
            (r'\\geq', r'\\geq'),           # ì´ë¯¸ ì˜¬ë°”ë¦„, í™•ì¸ìš©
            (r'\\leq', r'\\leq'),           # ì´ë¯¸ ì˜¬ë°”ë¦„, í™•ì¸ìš©
            (r'\\times', r'\\times'),       # ì´ë¯¸ ì˜¬ë°”ë¦„, í™•ì¸ìš©
        ]

        for corrupted, correct in corrupted_patterns:
            result = re.sub(corrupted, correct, result)

        # 3. ì—°ì†ëœ ë°±ìŠ¬ë˜ì‹œ ì •ë¦¬ (\\\\text â†’ \\text)
        result = re.sub(r'\\{2,}(text|frac|sqrt|sigma|Delta|propto|geq|leq|times)', r'\\\1', result)

        # 4. ëˆ„ë½ëœ ë°±ìŠ¬ë˜ì‹œ ì¶”ê°€ (text{ without backslash)
        result = re.sub(r'(?<!\\)text\{([^}]+)\}', r'\\text{\1}', result)

        return result

    # =========================================================================
    # Output Formatting
    # =========================================================================

    def format_structured_output(self, result: RefinedAnswer) -> str:
        """
        êµ¬ì¡°í™”ëœ í…ìŠ¤íŠ¸ ì¶œë ¥ í¬ë§·íŒ…

        Output:
            ### ğŸ“ ì¦ëª… ê³¼ì • (Derivation)
            ...
            ### ğŸ“š ê·¼ê±° ë§¤í•‘ (Evidence)
            ...
            ### ğŸ’¡ ìµœì¢… ê¶Œê³  (Recommendation)
            ...
        """
        parts = []

        def safe_str(value) -> str:
            """ë¦¬ìŠ¤íŠ¸ë‚˜ ë‹¤ë¥¸ íƒ€ì…ì„ ì•ˆì „í•˜ê²Œ ë¬¸ìì—´ë¡œ ë³€í™˜"""
            if isinstance(value, list):
                return ", ".join(str(v) for v in value)
            return str(value) if value else ""

        # 1. Derivation
        if result.derivation:
            parts.append("### ğŸ“ ì¦ëª… ê³¼ì • (Derivation)")
            parts.append(safe_str(result.derivation))
            parts.append("")

        # 2. Evidence Mapping
        if result.evidence_mapping:
            parts.append("### ğŸ“š ê·¼ê±° ë§¤í•‘ (Evidence)")
            for i, ev in enumerate(result.evidence_mapping, 1):
                verified = "âœ…" if ev.get("verified", False) else "âš ï¸"
                claim = safe_str(ev.get('claim', ''))
                source = safe_str(ev.get('source', 'ë¯¸í™•ì¸'))
                parts.append(f"{i}. {verified} **{claim}**")
                parts.append(f"   - ì¶œì²˜: {source}")
            parts.append("")

        # 3. Main Answer
        parts.append("### ğŸ“ ë‹µë³€")
        parts.append(safe_str(result.content))
        parts.append("")

        # 4. Clinical Insight (Phase 7.2)
        if result.clinical_insight:
            parts.append("### ğŸ”¬ ì„ìƒì  ì˜í–¥ ë¶„ì„ (Clinical Impact)")
            parts.append(safe_str(result.clinical_insight))
            parts.append("")

        # 5. Recommendation
        if result.recommendation:
            parts.append("### ğŸ’¡ ì„ìƒì  ê¶Œê³  (Recommendation)")
            parts.append(safe_str(result.recommendation))
            parts.append("")

        # 6. Quality Badge
        quality_badges = {
            AnswerQuality.EXCELLENT: "ğŸ† **ê²€ì¦ ì™„ë£Œ** (ì‹ ë¢°ë„: {:.0%})",
            AnswerQuality.GOOD: "âœ… **ì–‘í˜¸** (ì‹ ë¢°ë„: {:.0%})",
            AnswerQuality.NEEDS_REVISION: "âš ï¸ **ì£¼ì˜ í•„ìš”** (ì‹ ë¢°ë„: {:.0%})",
            AnswerQuality.UNRELIABLE: "âŒ **ì¬í™•ì¸ í•„ìš”** (ì‹ ë¢°ë„: {:.0%})",
        }
        badge = quality_badges.get(result.quality, "").format(result.final_confidence)
        parts.append(f"---\n{badge}")

        # 7. Corrections (if any)
        if result.corrections_made:
            parts.append("\n<details><summary>ğŸ”§ ìì²´ ê²€ì¦ì—ì„œ ìˆ˜ì •ëœ ì‚¬í•­</summary>\n")
            for corr in result.corrections_made:
                parts.append(f"- {safe_str(corr)}")
            parts.append("</details>")

        return "\n".join(parts)


# =============================================================================
# Singleton & Convenience
# =============================================================================

_engine_instance: Optional[TextReasoningEngine] = None


def get_text_reasoning_engine(config: Optional[TextReasoningConfig] = None) -> TextReasoningEngine:
    """TextReasoningEngine ì‹±ê¸€í†¤"""
    global _engine_instance
    if _engine_instance is None:
        _engine_instance = TextReasoningEngine(config)
    return _engine_instance


# =============================================================================
# Test
# =============================================================================

if __name__ == "__main__":
    logging.basicConfig(level=logging.INFO)

    # í…ŒìŠ¤íŠ¸ìš© ì§€ì‹
    test_knowledge = """
## í‘œì¤€ ì°¸ì¡° ìë£Œ
SNR âˆ âˆšDose ê´€ê³„ì— ì˜í•´:
- ì„ ëŸ‰ì„ 2ë°°ë¡œ ë†’ì´ë©´ SNRì€ âˆš2 â‰ˆ 1.414ë°° ì¦ê°€
- SNRì„ 2ë°°ë¡œ ë†’ì´ë ¤ë©´ ì„ ëŸ‰ì„ 4ë°°ë¡œ ì¦ê°€

## T-factor (Dance et al. 2011)
- DBTì—ì„œ 5cm ìœ ë°©ì˜ í‰ê·  T-factor: T â‰ˆ 0.94
- ì´ëŠ” í† ëª¨ì‹ í…Œì‹œìŠ¤ê°€ ê¸°ì¡´ 2D ëŒ€ë¹„ ì•½ 6% ë‚®ì€ ì„ ëŸ‰ íš¨ìœ¨ì„ ë³´ì„ì„ ì˜ë¯¸
"""

    engine = TextReasoningEngine()

    test_question = "SNRì„ 2ë°°ë¡œ ë†’ì´ë ¤ë©´ ì„ ëŸ‰ì„ ì–¼ë§ˆë‚˜ ì¦ê°€í•´ì•¼ í•˜ëŠ”ê°€? ì¦ëª…ê³¼ í•¨ê»˜ ì„¤ëª…í•´ì£¼ì„¸ìš”."

    print("=" * 60)
    print("Answering Twice Test")
    print("=" * 60)
    print(f"ì§ˆë¬¸: {test_question}")
    print("-" * 60)

    result = engine.reason(
        question=test_question,
        context="",
        physics_knowledge=test_knowledge
    )

    print("\n" + engine.format_structured_output(result))
