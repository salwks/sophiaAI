"""
BI-RADS Mammography Chapter Extractor
========================================
ACR BI-RADS 2025 PDFì—ì„œ Mammography ì±•í„° ì¶”ì¶œ (í…ìŠ¤íŠ¸, ì´ë¯¸ì§€, í…Œì´ë¸”)
"""

import json
import re
from pathlib import Path
from typing import Dict, List, Optional
import fitz  # PyMuPDF
from PIL import Image
import io

def extract_images_from_page(page: fitz.Page, page_num: int, output_dir: Path) -> List[Dict]:
    """
    í˜ì´ì§€ì—ì„œ ì´ë¯¸ì§€ ì¶”ì¶œ

    Args:
        page: PDF í˜ì´ì§€
        page_num: í˜ì´ì§€ ë²ˆí˜¸
        output_dir: ì´ë¯¸ì§€ ì €ì¥ ë””ë ‰í† ë¦¬

    Returns:
        ì´ë¯¸ì§€ ì •ë³´ ë¦¬ìŠ¤íŠ¸
    """
    images = []
    image_list = page.get_images(full=True)

    for img_index, img in enumerate(image_list):
        xref = img[0]

        try:
            base_image = page.parent.extract_image(xref)
            image_bytes = base_image["image"]
            image_ext = base_image["ext"]

            # ì´ë¯¸ì§€ ì €ì¥
            image_filename = f"page_{page_num:04d}_img_{img_index:02d}.{image_ext}"
            image_path = output_dir / "images" / image_filename
            image_path.parent.mkdir(parents=True, exist_ok=True)

            with open(image_path, "wb") as f:
                f.write(image_bytes)

            # ì´ë¯¸ì§€ í¬ê¸° í™•ì¸
            img_pil = Image.open(io.BytesIO(image_bytes))
            width, height = img_pil.size

            images.append({
                "filename": image_filename,
                "path": str(image_path.relative_to(output_dir)),
                "width": width,
                "height": height,
                "format": image_ext,
            })

        except Exception as e:
            print(f"  Warning: Failed to extract image {img_index} from page {page_num}: {e}")

    return images


def extract_tables_from_page(page: fitz.Page) -> List[Dict]:
    """
    í˜ì´ì§€ì—ì„œ í…Œì´ë¸” ì¶”ì¶œ (ê°„ë‹¨í•œ êµ¬ì¡° ê¸°ë°˜)

    Args:
        page: PDF í˜ì´ì§€

    Returns:
        í…Œì´ë¸” ì •ë³´ ë¦¬ìŠ¤íŠ¸
    """
    tables = []

    # PyMuPDFì˜ get_text("dict")ë¡œ ë¸”ë¡ ë‹¨ìœ„ ë¶„ì„
    blocks = page.get_text("dict")["blocks"]

    # í…Œì´ë¸”ì€ ë³´í†µ ì—¬ëŸ¬ ì¤„ì˜ êµ¬ì¡°í™”ëœ í…ìŠ¤íŠ¸ë¡œ í‘œí˜„ë¨
    # ê°„ë‹¨íˆ ì—°ì†ëœ ë¼ì¸ë“¤ì„ í…Œì´ë¸”ë¡œ ê°„ì£¼
    table_candidates = []
    current_table = []

    for block in blocks:
        if block["type"] == 0:  # Text block
            lines = block.get("lines", [])
            if len(lines) > 0:
                # ì—¬ëŸ¬ spanì´ ì¼ì • ê°„ê²©ìœ¼ë¡œ ë°°ì—´ë˜ë©´ í…Œì´ë¸”ë¡œ ê°„ì£¼
                for line in lines:
                    spans = line.get("spans", [])
                    if len(spans) >= 2:  # 2ê°œ ì´ìƒì˜ ì»¬ëŸ¼
                        current_table.append(" | ".join([span["text"] for span in spans]))
                    elif current_table:
                        # í…Œì´ë¸” ì¢…ë£Œ
                        if len(current_table) >= 3:  # ìµœì†Œ 3ì¤„ ì´ìƒ
                            table_candidates.append(current_table[:])
                        current_table = []

    # ë§ˆì§€ë§‰ í…Œì´ë¸” ì¶”ê°€
    if len(current_table) >= 3:
        table_candidates.append(current_table)

    # í…Œì´ë¸” ì •ë³´ ìƒì„±
    for idx, table in enumerate(table_candidates):
        tables.append({
            "index": idx,
            "rows": len(table),
            "content": "\n".join(table),
        })

    return tables


def extract_mammography_chapter(
    pdf_path: str,
    start_page: int = 18,
    end_page: int = 189,
    output_dir: Path = Path("data/raw/birads_2025"),
) -> Dict:
    """
    Mammography ì±•í„° ì¶”ì¶œ (í…ìŠ¤íŠ¸, ì´ë¯¸ì§€, í…Œì´ë¸”)

    Args:
        pdf_path: PDF íŒŒì¼ ê²½ë¡œ
        start_page: ì‹œì‘ í˜ì´ì§€ (1-based)
        end_page: ì¢…ë£Œ í˜ì´ì§€ (1-based)
        output_dir: ì¶œë ¥ ë””ë ‰í† ë¦¬

    Returns:
        ì¶”ì¶œ ê²°ê³¼ ë©”íƒ€ë°ì´í„°
    """
    output_dir = Path(output_dir)
    output_dir.mkdir(parents=True, exist_ok=True)

    doc = fitz.open(pdf_path)

    # 0-based ì¸ë±ìŠ¤ë¡œ ë³€í™˜
    start_idx = start_page - 1
    end_idx = end_page

    print(f"Extracting Mammography chapter: Pages {start_page}-{end_page} ({end_idx - start_idx} pages)")

    chapter_data = {
        "title": "ACR BI-RADS v2025 - Mammography",
        "source": pdf_path,
        "pages": {
            "start": start_page,
            "end": end_page,
            "total": end_idx - start_idx,
        },
        "sections": [],
        "total_images": 0,
        "total_tables": 0,
    }

    full_text = []

    for page_num in range(start_idx, end_idx):
        actual_page_num = page_num + 1
        page = doc[page_num]

        print(f"Processing page {actual_page_num}/{end_page}...", end="\r")

        # í…ìŠ¤íŠ¸ ì¶”ì¶œ
        text = page.get_text()

        # ì´ë¯¸ì§€ ì¶”ì¶œ
        images = extract_images_from_page(page, actual_page_num, output_dir)

        # í…Œì´ë¸” ì¶”ì¶œ
        tables = extract_tables_from_page(page)

        # ì„¹ì…˜ ì •ë³´ ì €ì¥
        section = {
            "page": actual_page_num,
            "text": text,
            "text_length": len(text),
            "images": images,
            "tables": tables,
        }

        chapter_data["sections"].append(section)
        chapter_data["total_images"] += len(images)
        chapter_data["total_tables"] += len(tables)

        full_text.append(text)

    print(f"\nâœ… Extraction complete!")

    # ì „ì²´ í…ìŠ¤íŠ¸ ì €ì¥
    full_text_content = "\n\n".join(full_text)
    text_file = output_dir / "mammography_full_text.txt"
    text_file.write_text(full_text_content, encoding="utf-8")

    # ë©”íƒ€ë°ì´í„° ì €ì¥
    metadata_file = output_dir / "mammography_metadata.json"
    metadata_file.write_text(
        json.dumps(chapter_data, ensure_ascii=False, indent=2),
        encoding="utf-8"
    )

    print(f"\nğŸ“„ Full text: {text_file}")
    print(f"ğŸ“Š Metadata: {metadata_file}")
    print(f"ğŸ–¼ï¸  Total images: {chapter_data['total_images']}")
    print(f"ğŸ“‹ Total tables: {chapter_data['total_tables']}")
    print(f"ğŸ“ Total text length: {len(full_text_content):,} characters")

    doc.close()

    return chapter_data


def segment_by_headings(text: str) -> List[Dict]:
    """
    í…ìŠ¤íŠ¸ë¥¼ ì œëª© ê¸°ì¤€ìœ¼ë¡œ ì„¹ì…˜ ë¶„í• 

    Args:
        text: ì „ì²´ í…ìŠ¤íŠ¸

    Returns:
        ì„¹ì…˜ ë¦¬ìŠ¤íŠ¸
    """
    sections = []

    # BI-RADS ë¬¸ì„œì˜ ì£¼ìš” í—¤ë”© íŒ¨í„´
    # I., II., III., A., B., 1., 2., Category 0-6 ë“±
    heading_patterns = [
        r'^(I{1,3}V?X?\.)\s+(.+)$',  # I., II., III., IV.
        r'^([A-Z]\.)\s+(.+)$',        # A., B., C.
        r'^(\d+\.)\s+(.+)$',          # 1., 2., 3.
        r'^(Category\s+\d[A-C]?)[:\.]?\s*(.*)$',  # Category 0-6
        r'^(APPENDIX\s+[A-Z])[:\-]?\s*(.+)$',     # APPENDIX A
    ]

    lines = text.split('\n')
    current_section = {
        "heading": "Introduction",
        "level": 0,
        "content": [],
    }

    for line in lines:
        line = line.strip()
        if not line:
            continue

        # í—¤ë”© ë§¤ì¹­ í™•ì¸
        is_heading = False
        for pattern in heading_patterns:
            match = re.match(pattern, line)
            if match:
                # ì´ì „ ì„¹ì…˜ ì €ì¥
                if current_section["content"]:
                    current_section["content"] = "\n".join(current_section["content"])
                    sections.append(current_section)

                # ìƒˆ ì„¹ì…˜ ì‹œì‘
                heading_marker = match.group(1)
                heading_text = match.group(2) if len(match.groups()) > 1 else ""

                current_section = {
                    "heading": f"{heading_marker} {heading_text}".strip(),
                    "level": 1,
                    "content": [],
                }
                is_heading = True
                break

        if not is_heading:
            current_section["content"].append(line)

    # ë§ˆì§€ë§‰ ì„¹ì…˜ ì¶”ê°€
    if current_section["content"]:
        current_section["content"] = "\n".join(current_section["content"])
        sections.append(current_section)

    return sections


def main():
    """ë©”ì¸ ì‹¤í–‰"""
    pdf_path = "/Users/sinjaeho/Documents/works/sophyAI/MARIA_KNOWLEDGE/DOCS/GUIDELINES/acr_bi_rads_2025_with_guides.pdf"
    output_dir = Path("data/raw/birads_2025")

    # Mammography ì±•í„° ì¶”ì¶œ
    chapter_data = extract_mammography_chapter(
        pdf_path=pdf_path,
        start_page=18,
        end_page=189,
        output_dir=output_dir,
    )

    # ì „ì²´ í…ìŠ¤íŠ¸ ë¡œë“œ
    full_text = (output_dir / "mammography_full_text.txt").read_text(encoding="utf-8")

    # ì„¹ì…˜ ë¶„í• 
    print("\n\n=== Segmenting by headings ===")
    sections = segment_by_headings(full_text)
    print(f"âœ… Found {len(sections)} sections")

    # ì„¹ì…˜ ì •ë³´ ì €ì¥
    sections_file = output_dir / "mammography_sections.json"
    sections_file.write_text(
        json.dumps(sections, ensure_ascii=False, indent=2),
        encoding="utf-8"
    )
    print(f"ğŸ“‹ Sections: {sections_file}")

    # ì£¼ìš” ì„¹ì…˜ ë¯¸ë¦¬ë³´ê¸°
    print("\n=== Major Sections ===")
    for i, section in enumerate(sections[:20]):
        heading = section["heading"]
        content_preview = section["content"][:100].replace('\n', ' ')
        print(f"  [{i+1}] {heading}")
        print(f"      {content_preview}...")

    print(f"\nâœ… Extraction complete! Total sections: {len(sections)}")


if __name__ == "__main__":
    main()
