#!/usr/bin/env python3
"""
MARIA-Mammo: LLM Query Parser Test Script
==========================================
LLM ÌååÏÑú Ï¢ÖÌï© ÌÖåÏä§Ìä∏
"""

import json
import sys
import time
from pathlib import Path

# ÌîÑÎ°úÏ†ùÌä∏ Î£®Ìä∏ Ï∂îÍ∞Ä
sys.path.insert(0, str(Path(__file__).parent.parent))

from src.search.query_parser import OllamaClient, LLMQueryParser, QueryParser


# ÌÖåÏä§Ìä∏ ÏøºÎ¶¨ (ÌïúÍµ≠Ïñ¥/ÏòÅÏñ¥ ÌòºÌï©)
TEST_QUERIES = [
    # === Í∏∞Î≥∏ ÏòÅÏñ¥ ===
    {
        "query": "DBT vs FFDM sensitivity comparison",
        "expected": {
            "modality": ["DBT", "FFDM"],
            "keywords_contain": ["dbt", "ffdm", "sensitivity"],
        }
    },
    {
        "query": "microcalcification detection in dense breast",
        "expected": {
            "pathology": ["calcification", "density"],
        }
    },

    # === Í∏∞Î≥∏ ÌïúÍµ≠Ïñ¥ ===
    {
        "query": "Ïú†Î∞© Î∞ÄÎèÑ Î∂ÑÎ•ò Í∏∞Ï§Ä",
        "expected": {
            "keywords_contain": ["breast", "density"],
        }
    },
    {
        "query": "ÏπòÎ∞ÄÏú†Î∞©ÏóêÏÑú ÎØ∏ÏÑ∏ÏÑùÌöåÌôî Í≤ÄÏ∂ú",
        "expected": {
            "pathology": ["calcification"],
        }
    },

    # === Î≥µÏû°Ìïú Ï°∞Í±¥ ===
    {
        "query": "Korean women DBT prospective study since 2020",
        "expected": {
            "modality": ["DBT"],
            "population": "Asian",
            "study_type": "prospective",
            "year_min": 2020,
        }
    },
    {
        "query": "BI-RADS 4 lesion positive predictive value",
        "expected": {
            "keywords_contain": ["bi-rads", "predictive"],
        }
    },

    # === ÎπÑÍµê Ïó∞Íµ¨ ===
    {
        "query": "contrast enhanced mammography vs MRI comparison",
        "expected": {
            "modality": ["CEM", "MRI"],
        }
    },
    {
        "query": "3D tomosynthesis vs 2D mammography sensitivity specificity",
        "expected": {
            "modality": ["DBT", "FFDM"],
            "keywords_contain": ["sensitivity", "specificity"],
        }
    },

    # === AI/CAD ===
    {
        "query": "AI CAD breast cancer detection performance",
        "expected": {
            "keywords_contain": ["ai", "cad", "detection"],
        }
    },
    {
        "query": "deep learning breast density classification",
        "expected": {
            "keywords_contain": ["deep", "learning", "density"],
        }
    },

    # === Ïó£ÏßÄ ÏºÄÏù¥Ïä§ ===
    {
        "query": "mammography screening",
        "expected": {
            "keywords_contain": ["mammography", "screening"],
        }
    },
    {
        "query": "breast cancer",
        "expected": {
            "keywords_contain": ["breast", "cancer"],
        }
    },
]


def check_expected(result, expected: dict) -> tuple[bool, list[str]]:
    """Í≤∞Í≥ºÍ∞Ä Í∏∞ÎåÄÍ∞íÍ≥º ÏùºÏπòÌïòÎäîÏßÄ ÌôïÏù∏"""
    passed = True
    issues = []

    # modality ÌôïÏù∏
    if "modality" in expected:
        result_modality = set(result.filters.modality or [])
        expected_modality = set(expected["modality"])
        if not expected_modality.issubset(result_modality):
            issues.append(f"Modality: expected {expected_modality}, got {result_modality}")
            passed = False

    # pathology ÌôïÏù∏
    if "pathology" in expected:
        result_pathology = set(result.filters.pathology or [])
        expected_pathology = set(expected["pathology"])
        if not expected_pathology.issubset(result_pathology):
            issues.append(f"Pathology: expected {expected_pathology}, got {result_pathology}")
            passed = False

    # population ÌôïÏù∏
    if "population" in expected:
        if result.filters.population != expected["population"]:
            issues.append(f"Population: expected {expected['population']}, got {result.filters.population}")
            passed = False

    # study_type ÌôïÏù∏
    if "study_type" in expected:
        if result.filters.study_type != expected["study_type"]:
            issues.append(f"Study type: expected {expected['study_type']}, got {result.filters.study_type}")
            passed = False

    # year_min ÌôïÏù∏
    if "year_min" in expected:
        if result.filters.year_min != expected["year_min"]:
            issues.append(f"Year min: expected {expected['year_min']}, got {result.filters.year_min}")
            passed = False

    # keywords Ìè¨Ìï® Ïó¨Î∂Ä ÌôïÏù∏
    if "keywords_contain" in expected:
        result_keywords = set(k.lower() for k in result.keywords)
        for kw in expected["keywords_contain"]:
            if not any(kw.lower() in rk for rk in result_keywords):
                issues.append(f"Keyword '{kw}' not found in {result.keywords}")
                passed = False

    return passed, issues


def test_parser(use_llm: bool = True):
    """ÌååÏÑú ÌÖåÏä§Ìä∏ Ïã§Ìñâ"""
    print("=" * 70)
    print(f"MARIA-Mammo Query Parser Test ({'LLM' if use_llm else 'Rule-based'})")
    print("=" * 70)

    # Ollama ÏÉÅÌÉú ÌôïÏù∏
    if use_llm:
        client = OllamaClient()
        if not client.is_available():
            print("\n‚ùå Ollama not available!")
            print("   Run: ollama serve")
            print("   Run: ollama pull llama3.2")
            print("\nFalling back to rule-based parser...")
            use_llm = False
        else:
            print(f"\n‚úÖ Ollama available (model: {client.model})")
        client.close()

    # ÌååÏÑú Ï¥àÍ∏∞Ìôî
    if use_llm:
        parser = LLMQueryParser(fallback_to_rule=True)
    else:
        parser = QueryParser()

    # Í≤∞Í≥º ÏàòÏßë
    results = []
    success_count = 0
    total_time = 0

    print("\n" + "-" * 70)

    for i, test_case in enumerate(TEST_QUERIES, 1):
        query = test_case["query"]
        expected = test_case["expected"]

        print(f"\n[{i}/{len(TEST_QUERIES)}] Query: {query}")

        start = time.time()
        try:
            parsed = parser.parse(query)
            elapsed = time.time() - start
            total_time += elapsed

            # Í≤∞Í≥º Ï∂úÎ†•
            print(f"   Keywords: {parsed.keywords[:5]}{'...' if len(parsed.keywords) > 5 else ''}")
            print(f"   MeSH: {parsed.mesh_terms[:3]}{'...' if len(parsed.mesh_terms) > 3 else ''}")
            print(f"   Filters: mod={parsed.filters.modality}, path={parsed.filters.pathology}, "
                  f"pop={parsed.filters.population}, study={parsed.filters.study_type}")
            print(f"   Intent: {parsed.intent[:60]}{'...' if len(parsed.intent) > 60 else ''}")
            print(f"   Time: {elapsed:.2f}s")

            # Í≤ÄÏ¶ù
            passed, issues = check_expected(parsed, expected)

            if passed:
                success_count += 1
                print("   ‚úÖ PASS")
            else:
                print("   ‚ö†Ô∏è  PARTIAL")
                for issue in issues:
                    print(f"      - {issue}")

            results.append({
                "query": query,
                "parsed": {
                    "keywords": parsed.keywords,
                    "mesh_terms": parsed.mesh_terms,
                    "filters": parsed.filters.model_dump() if hasattr(parsed.filters, 'model_dump') else str(parsed.filters),
                    "intent": parsed.intent,
                },
                "expected": expected,
                "time": elapsed,
                "passed": passed,
                "issues": issues,
            })

        except Exception as e:
            print(f"   ‚ùå ERROR: {e}")
            results.append({
                "query": query,
                "error": str(e),
                "passed": False,
            })

    # ÏöîÏïΩ
    print("\n" + "=" * 70)
    print("SUMMARY")
    print("=" * 70)
    print(f"Parser: {'LLM (llama3.2)' if use_llm else 'Rule-based'}")
    print(f"Total queries: {len(TEST_QUERIES)}")
    print(f"Passed: {success_count}/{len(TEST_QUERIES)} ({100*success_count/len(TEST_QUERIES):.1f}%)")
    print(f"Average time: {total_time/len(TEST_QUERIES):.2f}s")
    print(f"Total time: {total_time:.2f}s")

    # Í≤∞Í≥º Ï†ÄÏû•
    output_dir = Path("data/eval")
    output_dir.mkdir(parents=True, exist_ok=True)
    output_path = output_dir / "parser_test_results.json"

    with open(output_path, "w", encoding="utf-8") as f:
        json.dump(results, f, ensure_ascii=False, indent=2, default=str)
    print(f"\nResults saved to: {output_path}")

    # Ï†ïÎ¶¨
    if use_llm and hasattr(parser, 'close'):
        parser.close()

    return success_count, len(TEST_QUERIES)


def test_single(query: str, use_llm: bool = True):
    """Îã®Ïùº ÏøºÎ¶¨ ÌÖåÏä§Ìä∏"""
    print(f"Query: {query}\n")

    if use_llm:
        client = OllamaClient()
        if not client.is_available():
            print("‚ùå Ollama not available, using rule-based parser")
            use_llm = False
        client.close()

    if use_llm:
        parser = LLMQueryParser(fallback_to_rule=True)
    else:
        parser = QueryParser()

    start = time.time()
    parsed = parser.parse(query)
    elapsed = time.time() - start

    print(f"Keywords: {parsed.keywords}")
    print(f"MeSH terms: {parsed.mesh_terms}")
    print(f"Filters:")
    print(f"  - modality: {parsed.filters.modality}")
    print(f"  - pathology: {parsed.filters.pathology}")
    print(f"  - study_type: {parsed.filters.study_type}")
    print(f"  - population: {parsed.filters.population}")
    print(f"  - year_min: {parsed.filters.year_min}")
    print(f"  - year_max: {parsed.filters.year_max}")
    print(f"Intent: {parsed.intent}")
    print(f"Parser: {'LLM' if use_llm else 'Rule-based'}")
    print(f"Time: {elapsed:.2f}s")

    if use_llm and hasattr(parser, 'close'):
        parser.close()


def compare_parsers():
    """LLM vs Rule-based ÌååÏÑú ÎπÑÍµê"""
    print("=" * 70)
    print("Parser Comparison: LLM vs Rule-based")
    print("=" * 70)

    # Ollama ÌôïÏù∏
    client = OllamaClient()
    llm_available = client.is_available()
    client.close()

    if not llm_available:
        print("\n‚ùå Ollama not available. Cannot compare.")
        return

    llm_parser = LLMQueryParser(fallback_to_rule=False)
    rule_parser = QueryParser()

    test_queries = [
        "DBT vs FFDM for microcalcification",
        "Ïú†Î∞© Î∞ÄÎèÑ Î∂ÑÎ•ò BI-RADS",
        "Korean women breast screening since 2020",
        "meta-analysis contrast enhanced mammography",
    ]

    print("\n" + "-" * 70)

    for query in test_queries:
        print(f"\nüîç Query: {query}")

        # Rule-based
        start = time.time()
        rule_result = rule_parser.parse(query)
        rule_time = time.time() - start

        # LLM
        start = time.time()
        try:
            llm_result = llm_parser.parse(query)
            llm_time = time.time() - start
            llm_error = None
        except Exception as e:
            llm_time = 0
            llm_result = None
            llm_error = str(e)

        print(f"\n   [Rule-based] ({rule_time:.2f}s)")
        print(f"   Keywords: {rule_result.keywords[:5]}")
        print(f"   Filters: {rule_result.filters.modality}, {rule_result.filters.pathology}")

        if llm_result:
            print(f"\n   [LLM] ({llm_time:.2f}s)")
            print(f"   Keywords: {llm_result.keywords[:5]}")
            print(f"   Filters: {llm_result.filters.modality}, {llm_result.filters.pathology}")
            print(f"   Intent: {llm_result.intent[:50]}...")
        else:
            print(f"\n   [LLM] Error: {llm_error}")

    llm_parser.close()


if __name__ == "__main__":
    import argparse

    argparser = argparse.ArgumentParser(description="MARIA-Mammo Query Parser Test")
    argparser.add_argument("query", nargs="?", help="Single query to test")
    argparser.add_argument("--rule", action="store_true", help="Use rule-based parser only")
    argparser.add_argument("--compare", action="store_true", help="Compare LLM vs Rule-based")

    args = argparser.parse_args()

    if args.compare:
        compare_parsers()
    elif args.query:
        test_single(args.query, use_llm=not args.rule)
    else:
        test_parser(use_llm=not args.rule)
